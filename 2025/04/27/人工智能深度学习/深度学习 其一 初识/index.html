<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>深度学习 其一 图像识别算法 | 仓库</title><meta name="keywords" content="深度学习,图像识别算法"><meta name="author" content="fufhaha"><meta name="copyright" content="fufhaha"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="深度学习 其一 图像识别算法"><meta name="application-name" content="深度学习 其一 图像识别算法"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="深度学习 其一 图像识别算法"><meta property="og:url" content="https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/index.html"><meta property="og:site_name" content="仓库"><meta property="og:description" content="这是深度学习图像识别算法的笔记"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="/images/202504071512122.jpg"><meta property="article:author" content="fufhaha"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="/images/202504071512122.jpg"><meta name="description" content="这是深度学习图像识别算法的笔记"><link rel="shortcut icon" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"><link rel="canonical" href="https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><script async="async" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="var(--anzhiyu-main)"/><link rel="mask-icon" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif" color="#5bbad5"/><link rel="apple-touch-icon" sizes="180x180" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><link rel="apple-touch-icon-precomposed" sizes="180x180" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><link rel="icon" type="image/png" sizes="32x32" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><link rel="icon" type="image/png" sizes="16x16" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><link rel="bookmark" href="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2048-2732.jpg" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2732-2048.jpg" media="(device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1668-2388.jpg" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2388-1668.jpg" media="(device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1536-2048.jpg" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2048-1536.jpg" media="(device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1668-2224.jpg" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2224-1668.jpg" media="(device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1620-2160.jpg" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2160-1620.jpg" media="(device-width: 810px) and (device-height: 1080px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1290-2796.jpg" media="(device-width: 430px) and (device-height: 932px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2796-1290.jpg" media="(device-width: 430px) and (device-height: 932px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1179-2556.jpg" media="(device-width: 393px) and (device-height: 852px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2556-1179.jpg" media="(device-width: 393px) and (device-height: 852px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1284-2778.jpg" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2778-1284.jpg" media="(device-width: 428px) and (device-height: 926px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1170-2532.jpg" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2532-1170.jpg" media="(device-width: 390px) and (device-height: 844px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1125-2436.jpg" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2436-1125.jpg" media="(device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1242-2688.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2688-1242.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-828-1792.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1792-828.jpg" media="(device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1242-2208.jpg" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-2208-1242.jpg" media="(device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-750-1334.jpg" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1334-750.jpg" media="(device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-640-1136.jpg" media="(device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"/><link rel="apple-touch-startup-image" href="/img/siteicon/apple-splash-1136-640.jpg" media="(device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: {"enable":true,"title":"与数百名博主无限进步","addFriendPlaceholder":"昵称（请勿包含博客等字样）：\n网站地址（要求博客地址，请勿提交个人主页）：\n头像图片url（请提供尽可能清晰的图片，我会上传到我自己的图床）：\n描述：\n站点截图（可选）：\n"},
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2024/07/27/125766904/ba62475f396df9de3316a08ed9e65d86_5680958632268053399..png"},
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"🗺️风向已记录在航海日志，下次再见！","backTitle":"🛡️防御工事运作正常"},
  LA51: undefined,
  greetingBox: {"enable":true,"default":"🌰火堆噼啪作响，烤棉花糖的树枝已经削好啦","list":[{"greeting":"🌙星星在守夜，三只毛茸茸挤成团取暖","startTime":0,"endTime":5},{"greeting":"🌄露水收集罐满当当，晾着晒干的蘑菇串","startTime":6,"endTime":8},{"greeting":"🧺晒着太阳的干草堆，蜜蜂在篱笆外哼歌巡逻","startTime":9,"endTime":11},{"greeting":"🏰午休时间？扩建水下基地的好时机","startTime":12,"endTime":14},{"greeting":"柴火堆成小雪山，篱笆外插满了吓唬野猪的稻草人","startTime":15,"endTime":18},{"greeting":"🗡️夜巡开始！","startTime":19,"endTime":21},{"greeting":"🧶窗台摆满驱赶黑暗的萤石罐，此刻，被夜幕包围的你是安全的","startTime":22,"endTime":23}]},
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":null},
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: fufhaha","link":"链接: ","source":"来源: 仓库","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '仓库',
  title: '深度学习 其一 图像识别算法',
  postAI: '',
  pageFillDescription: '深度学习笔记：, 1.虚拟环境创建：, 虚拟环境五步：, 2.深度学习各函数：, 3.图像识别算法实验：, 1.用CNN实现图像分类：, CNN：卷积神经网络（图像处理方面）, 1. 卷积层（Convolution Layer）, 2. 激活函数（通常是 ReLU）, 3. 池化层（Pooling Layer）, 4. 全连接层（Fully Connected Layer）, 2.安装所需库, 3.从 TensorFlow 内置的 MNIST 数据集中加载训练集和测试集分为图像数据和对应的标签。, 4.最后跑完会生成一个模型文件cnn_model.h5, 神经网络：, 1.神经网络基本架构：, 结构上：, 连接方式（各层之间的连接细节）：, 一轮训练中的流程：, 向前传播：即从输入层到隐藏层最后到输出层这样一个传播过程最后得到一个预测结果这一步说白了就是进行一遍结构初始的三部分然后进入下面3个流程（那这个预测结果后面会被保存用来参与模型的形成吗）, 1.预测结果本身不会保存模型里面会用来和真实数据对比计算损失（那每轮训练都是根据数据集里面的一个数据来吗下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗我们能自己输入这个真实标签吗还是说只能用数据集提供好的数据集都会提供一个真实标签吗）, 1.训练的时候一般有3种：逐个样本（SGD）小批量（mini-batch）全量（batch）最常用的是min-batch小批量。每一轮会遍历整个数据集每个样本都会用到（这每一轮是什么意思是执行这8个步骤的一个循环吗那这一轮就用到了整个数据集的每个样本下一轮怎么办重复吗有什么意义？）, 2.数据集真实标签通常由数据集提供自带大部分公开数据集（如MINSTCIFAR-10）都自带有标签如果我们自己做数据集也可以自己输入真实标签（比如一张图片-》图片文件名文件夹名Excel表名）（那我们使用这些数据集的时候怎么调用这些标签呢？）, 损失函数：用输出层的预测结果和实际标签来计算损失（那这个实际标签怎么来定呢？这个预测结果如果不符合标签但是确实是正确的那该怎么办？错误的预测结果又有什么用？如果有损失那这个损失又有什么用？）, 1.标签通常在数据集里面比如说猫和狗这个类别通常是人工标注或已有数据集给出（怎么标注？数据集不是一张张图片吗）, 最简单的：为每张图配一个图片当做标签如猫狗（是创建一个图片的文件吗？）标注也可以用文件夹进行分类如catx2Fxxx.jpg（就是把数据集放在一个标签如cat命名的文件夹里吗然后编译器会自动识别文件名作为标签？）复杂任务如目标检测和分割时会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件记录每个目标的位置和类别, 2.如果预测结果不符合实际标签但又没有错那标签是错的要更改真实标签, 3.错误的预测结果的损失较大模型会知道自己哪里有问题并在会在后续训练中调整参数减少类似错误（这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？那模型训练过程中是不是还要加上一个逻辑使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样改变的大小幅度是多少？大吗？）, 1.每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度根据梯度往损失小的方向调整参数参数改变的幅度由学习率决定学习率大参数改变幅度大反之小学习率要选择适当不然改变会过大或者过小（即参数损失函数的导数）（那梯度是不是对损失函数求导然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？）, 4.损失越大模型预测结果就越差就要优化损失函数就是引导模型不断地优化, 反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义）, 1.反向传播就是要知道如果每个参数变大一点或者变小一点损失会怎么变化好针对调整（这个检测变化的过程是在当前训练中进行那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？）, 1.反向传播是一次性批量地对参数进行计算梯度然后优化器再一次性对参数进行调整, 2.计算每个参数对损失的影响是用链式法则（微积分）自动求导工具（如pytorchTensorFlow）自动完成（这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？）, 1.pytorch和TensorFlow都支持自动求导（autograd）只需定义网络结构和损失函数框架会自动追踪计算图自动完成反向传播和梯度计算（这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？）, 2.以pytorch为例调用求导：（这就是这几步的所有内容吗？）, 3.梯度就是损失函数对每个参数的导数表示参数每变化一点损失会怎么变梯度的方向指向损失增加最快的方向我们要反梯度方向调整参数让损失变小（那损失函数就是对每个参数求导然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？）, 1.是的参数就是损失函数的自变量所以可以对其进行求导损失函数就是对每个参数求导说白了就是对损失函数求导对应梯度就是对应的参数带入导函数, 优化器：利用反向传播计算出的度更新网络中的参数使模型表现更好（这就是说现在还是处于模型训练阶段对吧怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？）, 1.是的优化器是用于训练阶段的, 2.通过梯度来更新参数的具体操作是：新参数x3D旧参数-学习率*梯度（这个学习率又是什么为什么通过这个公式就能更新参数具体的原理是什么？）, 1.学习率是一个超参数用来控制每次参数更新的步长即变化幅度学习率过大会导致训练结果不稳定学习率过小会导致训练过慢导致结果可能最终陷入局部最优（始终在某一块局部训练）, 2.更新参考公式：, 3.参数是根据梯度来定而不是损失本身（参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数然后损失函数对梯度的计算起决定作用？）, 1.是的反向传播的核心是利用损失函数对每个参数求导求出梯度损失函数的形式决定了梯度的计算方式和数值梯度的大小和方向直接影响参数的更新（那这样损失又有什么用？直接求梯度不就行了根据梯度来进行优化损失函数的形式怎么定义有哪些？）, 4.第一次训练的参数一般是随机初始化的由深度学习框架自动生成一组初始参数（通常是很小的随机数）（这是怎么生成的？既然有参数那应该也有导入参数的变量吧那变量在哪里是怎么用的？）, 1.框架会自动为每一层参数分配变量并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值这样是让网络一开始就有多样性避免所有神经元学到一样的东西（这里神经元是什么？为什么要避免所有神经元学到一样的东西？）, 2.只需定义网络结构框架就会自动初始化参数深度学习笔记深度学习的输出结果通常是数据例如概率分类标签数值等这些结果可以用来判断数据集中是否符合某个要求虚拟环境创建在项目目录中创建名为的虚拟环境用也行用风格的命令或者直接在中激活进入不进也行打开等待的包管理工具名字是的缩写用来安装升级卸载包是一个开源的机器学习框架开发的用于构建和训练神经网络模型表示你想安装某个或多个包是一个用于科学计算的库提供多维数组高效矩阵计算等功能是深度学习常用的基础库之一还可以这样指定版本表示最小版本要求虚拟环境五步创建虚拟环境激活安装包使用一下然后清理掉防止忘了哪里留了残余文件暂时不用这个虚拟环境了退出一下回到系统默认的环境这个操作不会删除任何东西只是退出激活状态删除虚拟环境把环境包括文件彻底删除掉在里面深度学习各函数图像识别算法实验用实现图像分类卷积神经网络图像处理方面应用领域例子图像识别猫狗识别手写数字识别人脸识别图像分割医学图像分割道路分割视频分析安全监控动作识别自然语言处理文本分类比如情感分析的大致结构输入图像卷积层激活层池化层卷积层池化层全连接层输出卷积层使用小的滤波器在图像上滑动提取边缘纹理角点等特征类似人类用眼睛扫视一个图像局部激活函数通常是非线性转换帮助网络学到复杂的特征池化层用来降低图像尺寸减少计算量防止过拟合常用的是最大池化全连接层最后用全连接层类似普通神经网络进行分类输出安装所需库从内置的数据集中加载训练集和测试集分为图像数据和对应的标签表示从中引入一个自带的数据模块这是调用加载函数返回一个元组里面嵌套两个子元组深度学习一定要激活可以就在编译器的终端激活最后跑完会生成一个模型文件神经网络神经网络基本架构绝大多数的神经网络基本都可分为大部分输入层隐藏层输出层连接方式向前传播损失函数反向传播优化器结构上按顺序来分为输入层隐藏层输出层这三部分连接方式各层之间的连接细节连接方式一轮训练中的流程向前传播即从输入层到隐藏层最后到输出层这样一个传播过程最后得到一个预测结果这一步说白了就是进行一遍结构初始的三部分然后进入下面个流程那这个预测结果后面会被保存用来参与模型的形成吗预测结果本身不会保存模型里面会用来和真实数据对比计算损失那每轮训练都是根据数据集里面的一个数据来吗下一轮是不是就进入下一个数据集这个真实标签是我们自己输入的吗我们能自己输入这个真实标签吗还是说只能用数据集提供好的数据集都会提供一个真实标签吗训练的时候一般有种逐个样本小批量全量最常用的是小批量每一轮会遍历整个数据集每个样本都会用到这每一轮是什么意思是执行这个步骤的一个循环吗那这一轮就用到了整个数据集的每个样本下一轮怎么办重复吗有什么意义每一轮通常指一个一个里面进行多个小批量的循环训练在一轮中训练了所有的样本下一轮通常为了更好地泛化会打乱所有样本的数据多轮学习可以让模型不断学习而不只是只记住了死的数据而没有学会规律这个轮次是我们手动定义的吗数据集真实标签通常由数据集提供自带大部分公开数据集如都自带有标签如果我们自己做数据集也可以自己输入真实标签比如一张图片图片文件名文件夹名表名那我们使用这些数据集的时候怎么调用这些标签呢损失函数用输出层的预测结果和实际标签来计算损失那这个实际标签怎么来定呢这个预测结果如果不符合标签但是确实是正确的那该怎么办错误的预测结果又有什么用如果有损失那这个损失又有什么用标签通常在数据集里面比如说猫和狗这个类别通常是人工标注或已有数据集给出怎么标注数据集不是一张张图片吗最简单的为每张图配一个图片当做标签如猫狗是创建一个图片的文件吗标注也可以用文件夹进行分类如就是把数据集放在一个标签如命名的文件夹里吗然后编译器会自动识别文件名作为标签复杂任务如目标检测和分割时会用专门的标注工具如生成等标注文件记录每个目标的位置和类别如果预测结果不符合实际标签但又没有错那标签是错的要更改真实标签错误的预测结果的损失较大模型会知道自己哪里有问题并在会在后续训练中调整参数减少类似错误这个知道并调整的过程是怎么实现的是通过某个损失的大小来对参数做更改吗那模型训练过程中是不是还要加上一个逻辑使每次训练的时候让模型的参数往损失小的方向改变那如果是这样改变的大小幅度是多少大吗每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度根据梯度往损失小的方向调整参数参数改变的幅度由学习率决定学习率大参数改变幅度大反之小学习率要选择适当不然改变会过大或者过小即参数损失函数的导数那梯度是不是对损失函数求导然后对应参数带入导数中就是梯度学习率是我们自己选择的吗我们怎么选择损失越大模型预测结果就越差就要优化损失函数就是引导模型不断地优化反向传播根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响计算每个参数对损失的影响有什么作用这是怎么计算的那计算的影响的波动就是梯度吗这梯度有什么意义反向传播就是要知道如果每个参数变大一点或者变小一点损失会怎么变化好针对调整这个检测变化的过程是在当前训练中进行那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整反向传播是一次性批量地对参数进行计算梯度然后优化器再一次性对参数进行调整计算每个参数对损失的影响是用链式法则微积分自动求导工具如自动完成这个过程就是损失函数的运行操作吗具体来说和是怎么实现这个操作的我应该怎么做和都支持自动求导只需定义网络结构和损失函数框架会自动追踪计算图自动完成反向传播和梯度计算这里网络结构和损失函数是怎么定义的有固定的模版吗定义之后又是怎么调用的以为例调用求导这就是这几步的所有内容吗计算损失这参数又是什么意思自动反向传播计算所有参数的梯度优化器更新参数优化清零准备下一次迭代梯度就是损失函数对每个参数的导数表示参数每变化一点损失会怎么变梯度的方向指向损失增加最快的方向我们要反梯度方向调整参数让损失变小那损失函数就是对每个参数求导然后看参数的变化率吗再和真实标签进行比较那参数实际是函数里面的一个自变量吗所以才能求导是的参数就是损失函数的自变量所以可以对其进行求导损失函数就是对每个参数求导说白了就是对损失函数求导对应梯度就是对应的参数带入导函数优化器利用反向传播计算出的度更新网络中的参数使模型表现更好这就是说现在还是处于模型训练阶段对吧怎么能通过梯度来更新网络中的参数实际是根据每个参数损失函数大小来定的吗那第一次训练的参数是怎么形成的是自己输入的吗是的优化器是用于训练阶段的通过梯度来更新参数的具体操作是新参数旧参数学习率梯度这个学习率又是什么为什么通过这个公式就能更新参数具体的原理是什么学习率是一个超参数用来控制每次参数更新的步长即变化幅度学习率过大会导致训练结果不稳定学习率过小会导致训练过慢导致结果可能最终陷入局部最优始终在某一块局部训练更新参考公式模型参数如权重偏置学习率损失函数对参数的梯度其实就是上面那个新参数旧参数学习率梯度参数是根据梯度来定而不是损失本身参数的导数那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数然后损失函数对梯度的计算起决定作用是的反向传播的核心是利用损失函数对每个参数求导求出梯度损失函数的形式决定了梯度的计算方式和数值梯度的大小和方向直接影响参数的更新那这样损失又有什么用直接求梯度不就行了根据梯度来进行优化损失函数的形式怎么定义有哪些第一次训练的参数一般是随机初始化的由深度学习框架自动生成一组初始参数通常是很小的随机数这是怎么生成的既然有参数那应该也有导入参数的变量吧那变量在哪里是怎么用的框架会自动为每一层参数分配变量并用特定的方法如高斯分布均匀分布初始化等生成初始值这样是让网络一开始就有多样性避免所有神经元学到一样的东西这里神经元是什么为什么要避免所有神经元学到一样的东西只需定义网络结构框架就会自动初始化参数',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2025-04-27 00:00:00',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src="/images/帝君喝茶.gif" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src="/images/茶水.gif" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">仓库</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/c/" style="font-size: 1.05rem;">c++<sup>1</sup></a><a href="/tags/c-c/" style="font-size: 1.05rem;">c/c++<sup>11</sup></a><a href="/tags/%E5%88%B7%E9%A2%98/" style="font-size: 1.05rem;">刷题<sup>3</sup></a><a href="/tags/%E5%8C%97%E8%88%AA/" style="font-size: 1.05rem;">北航<sup>6</sup></a><a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 1.05rem;">博客<sup>1</sup></a><a href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">图像识别算法<sup>4</sup></a><a href="/tags/%E5%A4%87%E8%B5%9B/" style="font-size: 1.05rem;">备赛<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%A2%AF%E8%B5%9B/" style="font-size: 1.05rem;">天梯赛<sup>1</sup></a><a href="/tags/%E5%AE%9E%E6%88%98/" style="font-size: 1.05rem;">实战<sup>2</sup></a><a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/" style="font-size: 1.05rem;">嵌入式<sup>1</sup></a><a href="/tags/%E6%8C%87%E5%8D%97/" style="font-size: 1.05rem;">指南<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">数据结构<sup>1</sup></a><a href="/tags/%E6%96%B0%E9%A2%86%E5%9F%9F/" style="font-size: 1.05rem;">新领域<sup>1</sup></a><a href="/tags/%E6%B4%9B%E8%B0%B7/" style="font-size: 1.05rem;">洛谷<sup>3</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem;">深度学习<sup>4</sup></a><a href="/tags/%E6%B8%B8%E6%88%8F%E5%B0%8F%E9%A1%B9%E7%9B%AE/" style="font-size: 1.05rem;">游戏小项目<sup>1</sup></a><a href="/tags/%E6%B9%96%E5%8D%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6/" style="font-size: 1.05rem;">湖南工业大学<sup>1</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 1.05rem;">笔记<sup>13</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>6</sup></a><a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 1.05rem;">蓝桥杯<sup>1</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE%E8%AE%B2%E8%A7%A3/" style="font-size: 1.05rem;">项目讲解<sup>2</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/05/"><span class="card-archive-list-date">五月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/04/"><span class="card-archive-list-date">四月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/03/"><span class="card-archive-list-date">三月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/02/"><span class="card-archive-list-date">二月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">10</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">十一月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>深度学习</span></a><a class="article-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>图像识别算法</span></a></span></div></div><h1 class="post-title" itemprop="name headline">深度学习 其一 图像识别算法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-04-26T16:00:00.000Z" title="更新于 2025-04-27 00:00:00">2025-04-27</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="深度学习 其一 图像识别算法"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为长沙"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>长沙</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/images/202504071512122.jpg"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/"><header><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" tabindex="-1" itemprop="url">深度学习</a><a href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95/" tabindex="-1" itemprop="url">图像识别算法</a><h1 id="CrawlerTitle" itemprop="name headline">深度学习 其一 图像识别算法</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">fufhaha</span><time itemprop="dateCreated datePublished" datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time><time itemprop="dateCreated datePublished" datetime="2025-04-26T16:00:00.000Z" title="更新于 2025-04-27 00:00:00">2025-04-27</time></header><h1 id="深度学习笔记："><a href="#深度学习笔记：" class="headerlink" title="深度学习笔记："></a>深度学习笔记：</h1><p><strong>深度学习的输出结果通常是数据（例如概率、分类标签、数值等），这些结果可以用来判断数据集中是否符合某个要求。</strong></p>
<h1 id="1-虚拟环境创建："><a href="#1-虚拟环境创建：" class="headerlink" title="1.虚拟环境创建："></a>1.虚拟环境创建：</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在项目目录中创建名为 &quot;myenv&quot; 的虚拟环境</span></span><br><span class="line">python -m venv myenv#用git bash,cmd也行</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.\myenv\Scripts\activate.bat</span><br><span class="line">#用<span class="built_in">cmd</span>风格的shell命令</span><br><span class="line">#或者直接在<span class="built_in">cmd</span>中激活</span><br><span class="line">venv\Scripts\activate</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进入myenv（不进也行）打开git bash</span></span><br><span class="line">pip install numpy tensorflow</span><br><span class="line"><span class="comment">#等待...</span></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><code>pip</code></th>
<th align="center">Python 的包管理工具，名字是 “Pip Installs Packages” 的缩写，用来安装、升级、卸载 Python 包</th>
</tr>
</thead>
<tbody><tr>
<td><code>tensorflow</code></td>
<td align="center">是一个开源的机器学习框架，Google 开发的，用于构建和训练神经网络模型</td>
</tr>
<tr>
<td><code>install</code></td>
<td align="center">表示你想安装某个或多个包</td>
</tr>
<tr>
<td><code>numpy</code></td>
<td align="center">是一个用于科学计算的库，提供多维数组、高效矩阵计算等功能，是深度学习常用的基础库之一</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#还可以这样：</span></span><br><span class="line">pip install numpy==1.24.3 tensorflow&gt;=2.10</span><br><span class="line"><span class="comment">#== 指定版本</span></span><br><span class="line"><span class="comment">#&gt;= 表示最小版本要求</span></span><br></pre></td></tr></table></figure>

<h2 id="虚拟环境五步："><a href="#虚拟环境五步：" class="headerlink" title="虚拟环境五步："></a>虚拟环境五步：</h2><p>1.创建虚拟环境</p>
<p>2.激活</p>
<p>3.安装包</p>
<p>4.使用一下</p>
<p>5.然后清理掉（防止忘了哪里留了残余文件）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deactivate</span><br><span class="line"><span class="comment">#暂时不用这个虚拟环境了，退出一下，回到系统默认的 Python 环境。这个操作不会删除任何东西，只是退出激活状态。</span></span><br></pre></td></tr></table></figure>

<p>删除虚拟环境（把环境包括文件彻底删除掉）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在git bash里面</span></span><br><span class="line"><span class="built_in">rm</span> -rf myenv</span><br></pre></td></tr></table></figure>

<h1 id="2-深度学习各函数："><a href="#2-深度学习各函数：" class="headerlink" title="2.深度学习各函数："></a>2.深度学习各函数：</h1><h1 id="3-图像识别算法实验："><a href="#3-图像识别算法实验：" class="headerlink" title="3.图像识别算法实验："></a>3.图像识别算法实验：</h1><h2 id="1-用CNN实现图像分类："><a href="#1-用CNN实现图像分类：" class="headerlink" title="1.用CNN实现图像分类："></a>1.用CNN实现图像分类：</h2><h3 id="CNN：卷积神经网络（图像处理方面）"><a href="#CNN：卷积神经网络（图像处理方面）" class="headerlink" title="CNN：卷积神经网络（图像处理方面）"></a>CNN：卷积神经网络（图像处理方面）</h3><table>
<thead>
<tr>
<th>应用领域</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>图像识别</td>
<td>猫狗识别、手写数字识别（MNIST）、人脸识别</td>
</tr>
<tr>
<td>图像分割</td>
<td>医学图像分割、道路分割</td>
</tr>
<tr>
<td>视频分析</td>
<td>安全监控、动作识别</td>
</tr>
<tr>
<td>自然语言处理</td>
<td>文本分类（比如情感分析）</td>
</tr>
</tbody></table>
<p>CNN的大致结构：</p>
<p><strong>输入图像 → 卷积层 → 激活层(ReLU) → 池化层 → 卷积层 → 池化层 → 全连接层 → 输出</strong></p>
<h3 id="1-卷积层（Convolution-Layer）"><a href="#1-卷积层（Convolution-Layer）" class="headerlink" title="1. 卷积层（Convolution Layer）"></a>1. 卷积层（Convolution Layer）</h3><ul>
<li>使用小的滤波器（kernel）在图像上滑动，提取<strong>边缘、纹理、角点</strong>等特征。</li>
<li>类似人类用眼睛扫视一个图像局部。</li>
</ul>
<h3 id="2-激活函数（通常是-ReLU）"><a href="#2-激活函数（通常是-ReLU）" class="headerlink" title="2. 激活函数（通常是 ReLU）"></a>2. 激活函数（通常是 ReLU）</h3><ul>
<li>非线性转换，帮助网络学到复杂的特征。</li>
</ul>
<h3 id="3-池化层（Pooling-Layer）"><a href="#3-池化层（Pooling-Layer）" class="headerlink" title="3. 池化层（Pooling Layer）"></a>3. 池化层（Pooling Layer）</h3><ul>
<li>用来<strong>降低图像尺寸</strong>，减少计算量，防止过拟合。</li>
<li>常用的是最大池化（MaxPooling）。</li>
</ul>
<h3 id="4-全连接层（Fully-Connected-Layer）"><a href="#4-全连接层（Fully-Connected-Layer）" class="headerlink" title="4. 全连接层（Fully Connected Layer）"></a>4. 全连接层（Fully Connected Layer）</h3><ul>
<li>最后用全连接层（类似普通神经网络）进行分类输出。</li>
</ul>
<h2 id="2-安装所需库"><a href="#2-安装所需库" class="headerlink" title="2.安装所需库"></a>2.安装所需库</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#git bash</span></span><br><span class="line">pip install tensorflow keras numpy matplotlib</span><br></pre></td></tr></table></figure>

<h2 id="3-从-TensorFlow-内置的-MNIST-数据集中加载训练集和测试集，分为图像数据和对应的标签。"><a href="#3-从-TensorFlow-内置的-MNIST-数据集中加载训练集和测试集，分为图像数据和对应的标签。" class="headerlink" title="3.从 TensorFlow 内置的 MNIST 数据集中加载训练集和测试集，分为图像数据和对应的标签。"></a>3.从 TensorFlow 内置的 <strong>MNIST 数据集</strong>中加载训练集和测试集，分为图像数据和对应的标签。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> mnist<span class="comment">#表示从 TensorFlow 中引入一个自带的数据模块 —— mnist。</span></span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()<span class="comment">#这是调用加载函数，返回 一个元组，里面嵌套两个子元组：</span></span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure>

<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">D:\0001深度学习\<span class="title">porject01</span>\<span class="title">myenv</span>\<span class="title">Scripts</span>\<span class="title">activate</span></span></span><br><span class="line"><span class="function">#一定要激活，可以就在编译器的终端激活</span></span><br></pre></td></tr></table></figure>

<h2 id="4-最后跑完会生成一个模型文件cnn-model-h5"><a href="#4-最后跑完会生成一个模型文件cnn-model-h5" class="headerlink" title="4.最后跑完会生成一个模型文件cnn_model.h5"></a>4.最后跑完会生成一个模型文件cnn_model.h5</h2><h1 id="神经网络："><a href="#神经网络：" class="headerlink" title="神经网络："></a>神经网络：</h1><h2 id="1-神经网络基本架构："><a href="#1-神经网络基本架构：" class="headerlink" title="1.神经网络基本架构："></a>1.神经网络基本架构：</h2><p>绝大多数的神经网络基本都可分为8大部分：</p>
<p>1.输入层</p>
<p>2.隐藏层</p>
<p>3.输出层</p>
<p>4.连接方式</p>
<p>5.向前传播</p>
<p>6.损失函数</p>
<p>7.反向传播</p>
<p>8.优化器</p>
<h3 id="结构上："><a href="#结构上：" class="headerlink" title="结构上："></a>结构上：</h3><p>按顺序来分为 输入层-&gt;隐藏层-&gt;输出层 这三部分</p>
<h3 id="连接方式（各层之间的连接细节）："><a href="#连接方式（各层之间的连接细节）：" class="headerlink" title="连接方式（各层之间的连接细节）："></a>连接方式（各层之间的连接细节）：</h3><p>连接方式</p>
<h3 id="一轮训练中的流程："><a href="#一轮训练中的流程：" class="headerlink" title="一轮训练中的流程："></a>一轮训练中的流程：</h3><h4 id="向前传播：即从输入层到隐藏层，最后到输出层这样一个传播过程，最后得到一个预测结果，这一步说白了就是进行一遍结构初始的三部分，然后进入下面3个流程（那这个预测结果后面会被保存用来参与模型的形成吗）"><a href="#向前传播：即从输入层到隐藏层，最后到输出层这样一个传播过程，最后得到一个预测结果，这一步说白了就是进行一遍结构初始的三部分，然后进入下面3个流程（那这个预测结果后面会被保存用来参与模型的形成吗）" class="headerlink" title="向前传播：即从输入层到隐藏层，最后到输出层这样一个传播过程，最后得到一个预测结果，这一步说白了就是进行一遍结构初始的三部分，然后进入下面3个流程（那这个预测结果后面会被保存用来参与模型的形成吗）"></a>向前传播：即从输入层到隐藏层，最后到输出层这样一个传播过程，最后得到一个预测结果，这一步说白了就是进行一遍结构初始的三部分，然后进入下面3个流程（<strong>那这个预测结果后面会被保存用来参与模型的形成吗</strong>）</h4><h5 id="1-预测结果本身不会保存模型里面，会用来和真实数据对比，计算损失（那每轮训练都是根据数据集里面的一个数据来吗，下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗，我们能自己输入这个真实标签吗，还是说只能用数据集提供好的，数据集都会提供一个真实标签吗）"><a href="#1-预测结果本身不会保存模型里面，会用来和真实数据对比，计算损失（那每轮训练都是根据数据集里面的一个数据来吗，下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗，我们能自己输入这个真实标签吗，还是说只能用数据集提供好的，数据集都会提供一个真实标签吗）" class="headerlink" title="1.预测结果本身不会保存模型里面，会用来和真实数据对比，计算损失（那每轮训练都是根据数据集里面的一个数据来吗，下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗，我们能自己输入这个真实标签吗，还是说只能用数据集提供好的，数据集都会提供一个真实标签吗）"></a>1.预测结果本身不会保存模型里面，会用来和真实数据对比，计算损失（<strong>那每轮训练都是根据数据集里面的一个数据来吗，下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗，我们能自己输入这个真实标签吗，还是说只能用数据集提供好的，数据集都会提供一个真实标签吗</strong>）</h5><h5 id="1-训练的时候一般有3种：逐个样本（SGD），小批量（mini-batch），全量（batch），最常用的是min-batch小批量。每一轮会遍历整个数据集，每个样本都会用到（这每一轮是什么意思，是执行这8个步骤的一个循环吗，那这一轮就用到了整个数据集的每个样本，下一轮怎么办，重复吗，有什么意义？）"><a href="#1-训练的时候一般有3种：逐个样本（SGD），小批量（mini-batch），全量（batch），最常用的是min-batch小批量。每一轮会遍历整个数据集，每个样本都会用到（这每一轮是什么意思，是执行这8个步骤的一个循环吗，那这一轮就用到了整个数据集的每个样本，下一轮怎么办，重复吗，有什么意义？）" class="headerlink" title="1.训练的时候一般有3种：逐个样本（SGD），小批量（mini-batch），全量（batch），最常用的是min-batch小批量。每一轮会遍历整个数据集，每个样本都会用到（这每一轮是什么意思，是执行这8个步骤的一个循环吗，那这一轮就用到了整个数据集的每个样本，下一轮怎么办，重复吗，有什么意义？）"></a>1.训练的时候一般有3种：逐个样本（SGD），小批量（mini-batch），全量（batch），最常用的是min-batch小批量。每一轮会遍历整个数据集，每个样本都会用到（<strong>这每一轮是什么意思，是执行这8个步骤的一个循环吗，那这一轮就用到了整个数据集的每个样本，下一轮怎么办，重复吗，有什么意义？</strong>）</h5><p>1.每一轮通常指一个epoch，一个epoch里面进行多个小批量的循环训练，在一轮中训练了所有的样本，下一轮通常为了更好地泛化，会打乱所有样本的数据，多轮学习可以让模型不断学习，而不只是只记住了死的数据而没有学会规律（这个轮次是我们手动定义的吗？）</p>
<h5 id="2-数据集真实标签通常由数据集提供自带，大部分公开数据集（如MINST，CIFAR-10）都自带有标签，如果我们自己做数据集，也可以自己输入真实标签（比如一张图片-》图片文件名，文件夹名，Excel表名）（那我们使用这些数据集的时候怎么调用这些标签呢？）"><a href="#2-数据集真实标签通常由数据集提供自带，大部分公开数据集（如MINST，CIFAR-10）都自带有标签，如果我们自己做数据集，也可以自己输入真实标签（比如一张图片-》图片文件名，文件夹名，Excel表名）（那我们使用这些数据集的时候怎么调用这些标签呢？）" class="headerlink" title="2.数据集真实标签通常由数据集提供自带，大部分公开数据集（如MINST，CIFAR-10）都自带有标签，如果我们自己做数据集，也可以自己输入真实标签（比如一张图片-》图片文件名，文件夹名，Excel表名）（那我们使用这些数据集的时候怎么调用这些标签呢？）"></a>2.数据集真实标签通常由数据集提供自带，大部分公开数据集（如MINST，CIFAR-10）都自带有标签，如果我们自己做数据集，也可以自己输入真实标签（比如一张图片-》图片文件名，文件夹名，Excel表名）（<strong>那我们使用这些数据集的时候怎么调用这些标签呢？</strong>）</h5><h4 id="损失函数：用输出层的预测结果和实际标签来计算损失（那这个实际标签怎么来定呢？这个预测结果如果不符合标签，但是确实是正确的，那该怎么办？错误的预测结果又有什么用？如果有损失，那这个损失又有什么用？）"><a href="#损失函数：用输出层的预测结果和实际标签来计算损失（那这个实际标签怎么来定呢？这个预测结果如果不符合标签，但是确实是正确的，那该怎么办？错误的预测结果又有什么用？如果有损失，那这个损失又有什么用？）" class="headerlink" title="损失函数：用输出层的预测结果和实际标签来计算损失（那这个实际标签怎么来定呢？这个预测结果如果不符合标签，但是确实是正确的，那该怎么办？错误的预测结果又有什么用？如果有损失，那这个损失又有什么用？）"></a>损失函数：用输出层的预测结果和实际标签来计算损失（<strong>那这个实际标签怎么来定呢？这个预测结果如果不符合标签，但是确实是正确的，那该怎么办？错误的预测结果又有什么用？如果有损失，那这个损失又有什么用？</strong>）</h4><h5 id="1-标签通常在数据集里面，比如说猫和狗这个类别，通常是人工标注或已有数据集给出（怎么标注？数据集不是一张张图片吗）"><a href="#1-标签通常在数据集里面，比如说猫和狗这个类别，通常是人工标注或已有数据集给出（怎么标注？数据集不是一张张图片吗）" class="headerlink" title="1.标签通常在数据集里面，比如说猫和狗这个类别，通常是人工标注或已有数据集给出（怎么标注？数据集不是一张张图片吗）"></a>1.标签通常在数据集里面，比如说猫和狗这个类别，通常是人工标注或已有数据集给出（<strong>怎么标注？数据集不是一张张图片吗</strong>）</h5><h5 id="最简单的：为每张图配一个图片当做标签，如猫狗（是创建一个图片的文件吗？），标注也可以用文件夹进行分类，如cat-xxx-jpg（就是把数据集放在一个标签如cat命名的文件夹里吗，然后编译器会自动识别文件名作为标签？）复杂任务如目标检测和分割时，会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件，记录每个目标的位置和类别"><a href="#最简单的：为每张图配一个图片当做标签，如猫狗（是创建一个图片的文件吗？），标注也可以用文件夹进行分类，如cat-xxx-jpg（就是把数据集放在一个标签如cat命名的文件夹里吗，然后编译器会自动识别文件名作为标签？）复杂任务如目标检测和分割时，会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件，记录每个目标的位置和类别" class="headerlink" title="最简单的：为每张图配一个图片当做标签，如猫狗（是创建一个图片的文件吗？），标注也可以用文件夹进行分类，如cat&#x2F;xxx.jpg（就是把数据集放在一个标签如cat命名的文件夹里吗，然后编译器会自动识别文件名作为标签？）复杂任务如目标检测和分割时，会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件，记录每个目标的位置和类别"></a>最简单的：为每张图配一个图片当做标签，如猫狗（<strong>是创建一个图片的文件吗？</strong>），标注也可以用文件夹进行分类，如cat&#x2F;xxx.jpg（<strong>就是把数据集放在一个标签如cat命名的文件夹里吗，然后编译器会自动识别文件名作为标签？</strong>）复杂任务如目标检测和分割时，会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件，记录每个目标的位置和类别</h5><h5 id="2-如果预测结果不符合实际标签但又没有错，那标签是错的，要更改真实标签"><a href="#2-如果预测结果不符合实际标签但又没有错，那标签是错的，要更改真实标签" class="headerlink" title="2.如果预测结果不符合实际标签但又没有错，那标签是错的，要更改真实标签"></a>2.如果预测结果不符合实际标签但又没有错，那标签是错的，要更改真实标签</h5><h5 id="3-错误的预测结果的损失较大，模型会知道自己哪里有问题，并在会在后续训练中调整参数，减少类似错误（这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？，那模型训练过程中是不是还要加上一个逻辑，使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样，改变的大小幅度是多少？大吗？）"><a href="#3-错误的预测结果的损失较大，模型会知道自己哪里有问题，并在会在后续训练中调整参数，减少类似错误（这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？，那模型训练过程中是不是还要加上一个逻辑，使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样，改变的大小幅度是多少？大吗？）" class="headerlink" title="3.错误的预测结果的损失较大，模型会知道自己哪里有问题，并在会在后续训练中调整参数，减少类似错误（这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？，那模型训练过程中是不是还要加上一个逻辑，使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样，改变的大小幅度是多少？大吗？）"></a>3.错误的预测结果的损失较大，模型会知道自己哪里有问题，并在会在后续训练中调整参数，减少类似错误（<strong>这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？，那模型训练过程中是不是还要加上一个逻辑，使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样，改变的大小幅度是多少？大吗？</strong>）</h5><h5 id="1-每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度，根据梯度往损失小的方向调整参数，参数改变的幅度由学习率决定，学习率大，参数改变幅度大，反之小，学习率要选择适当，不然改变会过大或者过小（即参数损失函数的导数）（那梯度是不是对损失函数求导，然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？）"><a href="#1-每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度，根据梯度往损失小的方向调整参数，参数改变的幅度由学习率决定，学习率大，参数改变幅度大，反之小，学习率要选择适当，不然改变会过大或者过小（即参数损失函数的导数）（那梯度是不是对损失函数求导，然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？）" class="headerlink" title="1.每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度，根据梯度往损失小的方向调整参数，参数改变的幅度由学习率决定，学习率大，参数改变幅度大，反之小，学习率要选择适当，不然改变会过大或者过小（即参数损失函数的导数）（那梯度是不是对损失函数求导，然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？）"></a>1.每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度，根据梯度往损失小的方向调整参数，参数改变的幅度由学习率决定，学习率大，参数改变幅度大，反之小，学习率要选择适当，不然改变会过大或者过小（即参数损失函数的导数）（<strong>那梯度是不是对损失函数求导，然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？</strong>）</h5><h5 id="4-损失越大，模型预测结果就越差，就要优化，损失函数就是引导模型不断地优化"><a href="#4-损失越大，模型预测结果就越差，就要优化，损失函数就是引导模型不断地优化" class="headerlink" title="4.损失越大，模型预测结果就越差，就要优化，损失函数就是引导模型不断地优化"></a>4.损失越大，模型预测结果就越差，就要优化，损失函数就是引导模型不断地优化</h5><h4 id="反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义）"><a href="#反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义）" class="headerlink" title="反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义）"></a>反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（<strong>计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义</strong>）</h4><h5 id="1-反向传播就是要知道如果每个参数变大一点或者变小一点，损失会怎么变化，好针对调整（这个检测变化的过程是在当前训练中进行，那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？）"><a href="#1-反向传播就是要知道如果每个参数变大一点或者变小一点，损失会怎么变化，好针对调整（这个检测变化的过程是在当前训练中进行，那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？）" class="headerlink" title="1.反向传播就是要知道如果每个参数变大一点或者变小一点，损失会怎么变化，好针对调整（这个检测变化的过程是在当前训练中进行，那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？）"></a>1.反向传播就是要知道如果每个参数变大一点或者变小一点，损失会怎么变化，好针对调整（<strong>这个检测变化的过程是在当前训练中进行，那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？</strong>）</h5><h5 id="1-反向传播是一次性批量地对参数进行计算梯度，然后优化器再一次性对参数进行调整"><a href="#1-反向传播是一次性批量地对参数进行计算梯度，然后优化器再一次性对参数进行调整" class="headerlink" title="1.反向传播是一次性批量地对参数进行计算梯度，然后优化器再一次性对参数进行调整"></a>1.反向传播是一次性批量地对参数进行计算梯度，然后优化器再一次性对参数进行调整</h5><h5 id="2-计算每个参数对损失的影响是用链式法则（微积分），自动求导工具（如pytorch，TensorFlow）自动完成（这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？）"><a href="#2-计算每个参数对损失的影响是用链式法则（微积分），自动求导工具（如pytorch，TensorFlow）自动完成（这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？）" class="headerlink" title="2.计算每个参数对损失的影响是用链式法则（微积分），自动求导工具（如pytorch，TensorFlow）自动完成（这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？）"></a>2.计算每个参数对损失的影响是用链式法则（微积分），自动求导工具（如pytorch，TensorFlow）自动完成（<strong>这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？</strong>）</h5><h5 id="1-pytorch和TensorFlow都支持自动求导（autograd），只需定义网络结构和损失函数，框架会自动追踪计算图，自动完成反向传播和梯度计算（这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？）"><a href="#1-pytorch和TensorFlow都支持自动求导（autograd），只需定义网络结构和损失函数，框架会自动追踪计算图，自动完成反向传播和梯度计算（这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？）" class="headerlink" title="1.pytorch和TensorFlow都支持自动求导（autograd），只需定义网络结构和损失函数，框架会自动追踪计算图，自动完成反向传播和梯度计算（这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？）"></a>1.pytorch和TensorFlow都支持自动求导（autograd），只需定义网络结构和损失函数，框架会自动追踪计算图，自动完成反向传播和梯度计算（<strong>这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？</strong>）</h5><h5 id="2-以pytorch为例，调用求导：（这就是这几步的所有内容吗？）"><a href="#2-以pytorch为例，调用求导：（这就是这几步的所有内容吗？）" class="headerlink" title="2.以pytorch为例，调用求导：（这就是这几步的所有内容吗？）"></a>2.以pytorch为例，调用求导：（<strong>这就是这几步的所有内容吗？</strong>）</h5><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss=loss_fn(pre,label) <span class="comment">#计算损失（这参数又是什么意思？）</span></span><br><span class="line">loss.backward() <span class="comment">#自动反向传播，计算所有参数的梯度</span></span><br><span class="line">optimizer.step() <span class="comment">#优化器更新参数</span></span><br><span class="line">optimizer.zero_gard() <span class="comment">#优化清零，准备下一次迭代</span></span><br></pre></td></tr></table></figure>



<h5 id="3-梯度就是损失函数对每个参数的导数，表示参数每变化一点，损失会怎么变，梯度的方向指向损失增加最快的方向，我们要反梯度方向调整参数，让损失变小（那损失函数就是对每个参数求导，然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？）"><a href="#3-梯度就是损失函数对每个参数的导数，表示参数每变化一点，损失会怎么变，梯度的方向指向损失增加最快的方向，我们要反梯度方向调整参数，让损失变小（那损失函数就是对每个参数求导，然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？）" class="headerlink" title="3.梯度就是损失函数对每个参数的导数，表示参数每变化一点，损失会怎么变，梯度的方向指向损失增加最快的方向，我们要反梯度方向调整参数，让损失变小（那损失函数就是对每个参数求导，然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？）"></a>3.梯度就是损失函数对每个参数的导数，表示参数每变化一点，损失会怎么变，梯度的方向指向损失增加最快的方向，我们要反梯度方向调整参数，让损失变小（<strong>那损失函数就是对每个参数求导，然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？</strong>）</h5><h5 id="1-是的，参数就是损失函数的自变量，所以可以对其进行求导，损失函数就是对每个参数求导，说白了就是对损失函数求导，对应梯度就是对应的参数带入导函数"><a href="#1-是的，参数就是损失函数的自变量，所以可以对其进行求导，损失函数就是对每个参数求导，说白了就是对损失函数求导，对应梯度就是对应的参数带入导函数" class="headerlink" title="1.是的，参数就是损失函数的自变量，所以可以对其进行求导，损失函数就是对每个参数求导，说白了就是对损失函数求导，对应梯度就是对应的参数带入导函数"></a>1.是的，参数就是损失函数的自变量，所以可以对其进行求导，损失函数就是对每个参数求导，说白了就是对损失函数求导，对应梯度就是对应的参数带入导函数</h5><h4 id="优化器：利用反向传播计算出的度，更新网络中的参数，使模型表现更好（这就是说现在还是处于模型训练阶段对吧，怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？）"><a href="#优化器：利用反向传播计算出的度，更新网络中的参数，使模型表现更好（这就是说现在还是处于模型训练阶段对吧，怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？）" class="headerlink" title="优化器：利用反向传播计算出的度，更新网络中的参数，使模型表现更好（这就是说现在还是处于模型训练阶段对吧，怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？）"></a>优化器：利用反向传播计算出的度，更新网络中的参数，使模型表现更好（<strong>这就是说现在还是处于模型训练阶段对吧，怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？</strong>）</h4><h5 id="1-是的，优化器是用于训练阶段的"><a href="#1-是的，优化器是用于训练阶段的" class="headerlink" title="1.是的，优化器是用于训练阶段的"></a>1.是的，优化器是用于训练阶段的</h5><h5 id="2-通过梯度来更新参数的具体操作是：新参数-旧参数-学习率-梯度（这个学习率又是什么，为什么通过这个公式就能更新参数，具体的原理是什么？）"><a href="#2-通过梯度来更新参数的具体操作是：新参数-旧参数-学习率-梯度（这个学习率又是什么，为什么通过这个公式就能更新参数，具体的原理是什么？）" class="headerlink" title="2.通过梯度来更新参数的具体操作是：新参数&#x3D;旧参数-学习率*梯度（这个学习率又是什么，为什么通过这个公式就能更新参数，具体的原理是什么？）"></a>2.通过梯度来更新参数的具体操作是：新参数&#x3D;旧参数-学习率*梯度（<strong>这个学习率又是什么，为什么通过这个公式就能更新参数，具体的原理是什么？</strong>）</h5><h5 id="1-学习率是一个超参数，用来控制每次参数更新的步长，即变化幅度，学习率过大，会导致训练结果不稳定，学习率过小，会导致训练过慢，导致结果可能最终陷入局部最优（始终在某一块局部训练）"><a href="#1-学习率是一个超参数，用来控制每次参数更新的步长，即变化幅度，学习率过大，会导致训练结果不稳定，学习率过小，会导致训练过慢，导致结果可能最终陷入局部最优（始终在某一块局部训练）" class="headerlink" title="1.学习率是一个超参数，用来控制每次参数更新的步长，即变化幅度，学习率过大，会导致训练结果不稳定，学习率过小，会导致训练过慢，导致结果可能最终陷入局部最优（始终在某一块局部训练）"></a>1.学习率是一个超参数，用来控制每次参数更新的步长，即变化幅度，学习率过大，会导致训练结果不稳定，学习率过小，会导致训练过慢，导致结果可能最终陷入局部最优（始终在某一块局部训练）</h5><h5 id="2-更新参考公式："><a href="#2-更新参考公式：" class="headerlink" title="2.更新参考公式："></a>2.更新参考公式：</h5><ul>
<li><p>$$<br>θnew&#x3D;θold−η*⋅∂θ&#x2F;∂L<br>$$</p>
</li>
<li><p><em>θ</em>：模型参数（如权重、偏置）</p>
</li>
<li><p><em>η</em>：学习率</p>
</li>
<li><p>∂θ&#x2F;∂L：损失函数对参数的梯度</p>
</li>
<li><p>其实就是上面那个  新参数&#x3D;旧参数-学习率*梯度</p>
</li>
</ul>
<h5 id="3-参数是根据梯度来定，而不是损失本身（参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数，然后损失函数对梯度的计算起决定作用？）"><a href="#3-参数是根据梯度来定，而不是损失本身（参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数，然后损失函数对梯度的计算起决定作用？）" class="headerlink" title="3.参数是根据梯度来定，而不是损失本身（参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数，然后损失函数对梯度的计算起决定作用？）"></a>3.参数是根据梯度来定，而不是损失本身（<strong>参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数，然后损失函数对梯度的计算起决定作用？</strong>）</h5><h5 id="1-是的，反向传播的核心是利用损失函数对每个参数求导求出梯度，损失函数的形式决定了梯度的计算方式和数值，梯度的大小和方向直接影响参数的更新（那这样损失又有什么用？直接求梯度不就行了，根据梯度来进行优化，损失函数的形式怎么定义，有哪些？）"><a href="#1-是的，反向传播的核心是利用损失函数对每个参数求导求出梯度，损失函数的形式决定了梯度的计算方式和数值，梯度的大小和方向直接影响参数的更新（那这样损失又有什么用？直接求梯度不就行了，根据梯度来进行优化，损失函数的形式怎么定义，有哪些？）" class="headerlink" title="1.是的，反向传播的核心是利用损失函数对每个参数求导求出梯度，损失函数的形式决定了梯度的计算方式和数值，梯度的大小和方向直接影响参数的更新（那这样损失又有什么用？直接求梯度不就行了，根据梯度来进行优化，损失函数的形式怎么定义，有哪些？）"></a>1.是的，反向传播的核心是利用损失函数对每个参数求导求出梯度，损失函数的形式决定了梯度的计算方式和数值，梯度的大小和方向直接影响参数的更新（<strong>那这样损失又有什么用？直接求梯度不就行了，根据梯度来进行优化，损失函数的形式怎么定义，有哪些？</strong>）</h5><h5 id="4-第一次训练的参数一般是随机初始化的，由深度学习框架自动生成一组初始参数（通常是很小的随机数）（这是怎么生成的？既然有参数，那应该也有导入参数的变量吧，那变量在哪里，是怎么用的？）"><a href="#4-第一次训练的参数一般是随机初始化的，由深度学习框架自动生成一组初始参数（通常是很小的随机数）（这是怎么生成的？既然有参数，那应该也有导入参数的变量吧，那变量在哪里，是怎么用的？）" class="headerlink" title="4.第一次训练的参数一般是随机初始化的，由深度学习框架自动生成一组初始参数（通常是很小的随机数）（这是怎么生成的？既然有参数，那应该也有导入参数的变量吧，那变量在哪里，是怎么用的？）"></a>4.第一次训练的参数一般是随机初始化的，由深度学习框架自动生成一组初始参数（通常是很小的随机数）（<strong>这是怎么生成的？既然有参数，那应该也有导入参数的变量吧，那变量在哪里，是怎么用的</strong>？）</h5><h5 id="1-框架会自动为每一层参数分配变量，并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值，这样是让网络一开始就有多样性，避免所有神经元学到一样的东西（这里神经元是什么？为什么要避免所有神经元学到一样的东西？）"><a href="#1-框架会自动为每一层参数分配变量，并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值，这样是让网络一开始就有多样性，避免所有神经元学到一样的东西（这里神经元是什么？为什么要避免所有神经元学到一样的东西？）" class="headerlink" title="1.框架会自动为每一层参数分配变量，并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值，这样是让网络一开始就有多样性，避免所有神经元学到一样的东西（这里神经元是什么？为什么要避免所有神经元学到一样的东西？）"></a>1.框架会自动为每一层参数分配变量，并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值，这样是让网络一开始就有多样性，避免所有神经元学到一样的东西（<strong>这里神经元是什么？为什么要避免所有神经元学到一样的东西？</strong>）</h5><h5 id="2-只需定义网络结构，框架就会自动初始化参数"><a href="#2-只需定义网络结构，框架就会自动初始化参数" class="headerlink" title="2.只需定义网络结构，框架就会自动初始化参数"></a>2.只需定义网络结构，框架就会自动初始化参数</h5></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif" title="头像" alt="头像"></a><div class="post-copyright__author_name">fufhaha</div><div class="post-copyright__author_desc">存储知识</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/')">深度学习 其一 图像识别算法</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=深度学习 其一 图像识别算法&amp;url=https://huhuha.top/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%80%20%E5%88%9D%E8%AF%86/&amp;pic=/images/202504071512122.jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://huhuha.top" target="_blank">仓库</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>深度学习<span class="tagsPageCount">4</span></a><a class="post-meta__box__tags" href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>图像识别算法<span class="tagsPageCount">4</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="/images/202504071512575.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/04/06/C%E6%88%96C++%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20%E5%85%B6%E4%B8%80/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512548.jpg" onerror="onerror=null;src='/images/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">数据结构学习笔记 其一</div></div></a></div><div class="next-post pull-right"><a href="/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%20%E5%85%B6%E4%BA%8C%20%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512122.jpg" onerror="onerror=null;src='/images/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习 其二 神经网络和卷积神经网络</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/04/27/%E5%A4%87%E8%B5%9B/%E5%A4%87%E8%B5%9B%20%E5%85%B6%E4%B8%80%20%20%20%E6%B9%96%E5%8C%97%E4%BF%A1%E5%88%9B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="备赛 其一 湖北信创人工智能"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071511317.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-04-27</div><div class="title">备赛 其一 湖北信创人工智能</div></div></a></div><div><a href="/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%20%E5%85%B6%E4%BA%8C%20%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="深度学习 其二 神经网络和卷积神经网络"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512122.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-04-27</div><div class="title">深度学习 其二 神经网络和卷积神经网络</div></div></a></div><div><a href="/2025/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%89%20OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" title="深度学习 其三 OpenCV图像处理"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512122.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-04-28</div><div class="title">深度学习 其三 OpenCV图像处理</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif" onerror="this.onerror=null;this.src='/images/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/%E5%B8%9D%E5%90%9B%E5%96%9D%E8%8C%B6.gif" alt="status"/></div></div><div class="author-info__description">在这里随便逛逛</div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎！</div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://bu.dusays.com/2023/01/13/63c02edf44033.png) center center / 100% no-repeat"></div><div class="back face" style="background: url(https://bu.dusays.com/2023/05/13/645fa415e8694.png) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">深度学习笔记：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">1.虚拟环境创建：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%BA%94%E6%AD%A5%EF%BC%9A"><span class="toc-number">2.1.</span> <span class="toc-text">虚拟环境五步：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%90%84%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">2.深度学习各函数：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95%E5%AE%9E%E9%AA%8C%EF%BC%9A"><span class="toc-number">4.</span> <span class="toc-text">3.图像识别算法实验：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%94%A8CNN%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%EF%BC%9A"><span class="toc-number">4.1.</span> <span class="toc-text">1.用CNN实现图像分类：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CNN%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E6%96%B9%E9%9D%A2%EF%BC%89"><span class="toc-number">4.1.1.</span> <span class="toc-text">CNN：卷积神经网络（图像处理方面）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%88Convolution-Layer%EF%BC%89"><span class="toc-number">4.1.2.</span> <span class="toc-text">1. 卷积层（Convolution Layer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF-ReLU%EF%BC%89"><span class="toc-number">4.1.3.</span> <span class="toc-text">2. 激活函数（通常是 ReLU）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%88Pooling-Layer%EF%BC%89"><span class="toc-number">4.1.4.</span> <span class="toc-text">3. 池化层（Pooling Layer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%EF%BC%88Fully-Connected-Layer%EF%BC%89"><span class="toc-number">4.1.5.</span> <span class="toc-text">4. 全连接层（Fully Connected Layer）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85%E6%89%80%E9%9C%80%E5%BA%93"><span class="toc-number">4.2.</span> <span class="toc-text">2.安装所需库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BB%8E-TensorFlow-%E5%86%85%E7%BD%AE%E7%9A%84-MNIST-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E5%8A%A0%E8%BD%BD%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%EF%BC%8C%E5%88%86%E4%B8%BA%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%92%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E6%A0%87%E7%AD%BE%E3%80%82"><span class="toc-number">4.3.</span> <span class="toc-text">3.从 TensorFlow 内置的 MNIST 数据集中加载训练集和测试集，分为图像数据和对应的标签。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9C%80%E5%90%8E%E8%B7%91%E5%AE%8C%E4%BC%9A%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AA%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6cnn-model-h5"><span class="toc-number">4.4.</span> <span class="toc-text">4.最后跑完会生成一个模型文件cnn_model.h5</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A"><span class="toc-number">5.</span> <span class="toc-text">神经网络：</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%EF%BC%9A"><span class="toc-number">5.1.</span> <span class="toc-text">1.神经网络基本架构：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E4%B8%8A%EF%BC%9A"><span class="toc-number">5.1.1.</span> <span class="toc-text">结构上：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E6%96%B9%E5%BC%8F%EF%BC%88%E5%90%84%E5%B1%82%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%9E%E6%8E%A5%E7%BB%86%E8%8A%82%EF%BC%89%EF%BC%9A"><span class="toc-number">5.1.2.</span> <span class="toc-text">连接方式（各层之间的连接细节）：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E8%BD%AE%E8%AE%AD%E7%BB%83%E4%B8%AD%E7%9A%84%E6%B5%81%E7%A8%8B%EF%BC%9A"><span class="toc-number">5.1.3.</span> <span class="toc-text">一轮训练中的流程：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%91%E5%89%8D%E4%BC%A0%E6%92%AD%EF%BC%9A%E5%8D%B3%E4%BB%8E%E8%BE%93%E5%85%A5%E5%B1%82%E5%88%B0%E9%9A%90%E8%97%8F%E5%B1%82%EF%BC%8C%E6%9C%80%E5%90%8E%E5%88%B0%E8%BE%93%E5%87%BA%E5%B1%82%E8%BF%99%E6%A0%B7%E4%B8%80%E4%B8%AA%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%EF%BC%8C%E6%9C%80%E5%90%8E%E5%BE%97%E5%88%B0%E4%B8%80%E4%B8%AA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%EF%BC%8C%E8%BF%99%E4%B8%80%E6%AD%A5%E8%AF%B4%E7%99%BD%E4%BA%86%E5%B0%B1%E6%98%AF%E8%BF%9B%E8%A1%8C%E4%B8%80%E9%81%8D%E7%BB%93%E6%9E%84%E5%88%9D%E5%A7%8B%E7%9A%84%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%8C%E7%84%B6%E5%90%8E%E8%BF%9B%E5%85%A5%E4%B8%8B%E9%9D%A23%E4%B8%AA%E6%B5%81%E7%A8%8B%EF%BC%88%E9%82%A3%E8%BF%99%E4%B8%AA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%90%8E%E9%9D%A2%E4%BC%9A%E8%A2%AB%E4%BF%9D%E5%AD%98%E7%94%A8%E6%9D%A5%E5%8F%82%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%A2%E6%88%90%E5%90%97%EF%BC%89"><span class="toc-number">5.1.3.1.</span> <span class="toc-text">向前传播：即从输入层到隐藏层，最后到输出层这样一个传播过程，最后得到一个预测结果，这一步说白了就是进行一遍结构初始的三部分，然后进入下面3个流程（那这个预测结果后面会被保存用来参与模型的形成吗）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E6%9C%AC%E8%BA%AB%E4%B8%8D%E4%BC%9A%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B%E9%87%8C%E9%9D%A2%EF%BC%8C%E4%BC%9A%E7%94%A8%E6%9D%A5%E5%92%8C%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%8D%9F%E5%A4%B1%EF%BC%88%E9%82%A3%E6%AF%8F%E8%BD%AE%E8%AE%AD%E7%BB%83%E9%83%BD%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E9%9B%86%E9%87%8C%E9%9D%A2%E7%9A%84%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E6%9D%A5%E5%90%97%EF%BC%8C%E4%B8%8B%E4%B8%80%E8%BD%AE%E6%98%AF%E4%B8%8D%E6%98%AF%E5%B0%B1%E8%BF%9B%E5%85%A5%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9F%E8%BF%99%E4%B8%AA%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E6%98%AF%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E8%BE%93%E5%85%A5%E7%9A%84%E5%90%97%EF%BC%8C%E6%88%91%E4%BB%AC%E8%83%BD%E8%87%AA%E5%B7%B1%E8%BE%93%E5%85%A5%E8%BF%99%E4%B8%AA%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E5%90%97%EF%BC%8C%E8%BF%98%E6%98%AF%E8%AF%B4%E5%8F%AA%E8%83%BD%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E6%8F%90%E4%BE%9B%E5%A5%BD%E7%9A%84%EF%BC%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E9%83%BD%E4%BC%9A%E6%8F%90%E4%BE%9B%E4%B8%80%E4%B8%AA%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E5%90%97%EF%BC%89"><span class="toc-number">5.1.3.1.1.</span> <span class="toc-text">1.预测结果本身不会保存模型里面，会用来和真实数据对比，计算损失（那每轮训练都是根据数据集里面的一个数据来吗，下一轮是不是就进入下一个数据集？这个真实标签是我们自己输入的吗，我们能自己输入这个真实标签吗，还是说只能用数据集提供好的，数据集都会提供一个真实标签吗）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E8%AE%AD%E7%BB%83%E7%9A%84%E6%97%B6%E5%80%99%E4%B8%80%E8%88%AC%E6%9C%893%E7%A7%8D%EF%BC%9A%E9%80%90%E4%B8%AA%E6%A0%B7%E6%9C%AC%EF%BC%88SGD%EF%BC%89%EF%BC%8C%E5%B0%8F%E6%89%B9%E9%87%8F%EF%BC%88mini-batch%EF%BC%89%EF%BC%8C%E5%85%A8%E9%87%8F%EF%BC%88batch%EF%BC%89%EF%BC%8C%E6%9C%80%E5%B8%B8%E7%94%A8%E7%9A%84%E6%98%AFmin-batch%E5%B0%8F%E6%89%B9%E9%87%8F%E3%80%82%E6%AF%8F%E4%B8%80%E8%BD%AE%E4%BC%9A%E9%81%8D%E5%8E%86%E6%95%B4%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%E9%83%BD%E4%BC%9A%E7%94%A8%E5%88%B0%EF%BC%88%E8%BF%99%E6%AF%8F%E4%B8%80%E8%BD%AE%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D%EF%BC%8C%E6%98%AF%E6%89%A7%E8%A1%8C%E8%BF%998%E4%B8%AA%E6%AD%A5%E9%AA%A4%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BE%AA%E7%8E%AF%E5%90%97%EF%BC%8C%E9%82%A3%E8%BF%99%E4%B8%80%E8%BD%AE%E5%B0%B1%E7%94%A8%E5%88%B0%E4%BA%86%E6%95%B4%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%AF%8F%E4%B8%AA%E6%A0%B7%E6%9C%AC%EF%BC%8C%E4%B8%8B%E4%B8%80%E8%BD%AE%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%8C%E9%87%8D%E5%A4%8D%E5%90%97%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E6%84%8F%E4%B9%89%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.1.2.</span> <span class="toc-text">1.训练的时候一般有3种：逐个样本（SGD），小批量（mini-batch），全量（batch），最常用的是min-batch小批量。每一轮会遍历整个数据集，每个样本都会用到（这每一轮是什么意思，是执行这8个步骤的一个循环吗，那这一轮就用到了整个数据集的每个样本，下一轮怎么办，重复吗，有什么意义？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E9%80%9A%E5%B8%B8%E7%94%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E6%8F%90%E4%BE%9B%E8%87%AA%E5%B8%A6%EF%BC%8C%E5%A4%A7%E9%83%A8%E5%88%86%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%A6%82MINST%EF%BC%8CCIFAR-10%EF%BC%89%E9%83%BD%E8%87%AA%E5%B8%A6%E6%9C%89%E6%A0%87%E7%AD%BE%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E5%81%9A%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E8%87%AA%E5%B7%B1%E8%BE%93%E5%85%A5%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%EF%BC%88%E6%AF%94%E5%A6%82%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%89%87-%E3%80%8B%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%E5%90%8D%EF%BC%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%90%8D%EF%BC%8CExcel%E8%A1%A8%E5%90%8D%EF%BC%89%EF%BC%88%E9%82%A3%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8%E8%BF%99%E4%BA%9B%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%97%B6%E5%80%99%E6%80%8E%E4%B9%88%E8%B0%83%E7%94%A8%E8%BF%99%E4%BA%9B%E6%A0%87%E7%AD%BE%E5%91%A2%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.1.3.</span> <span class="toc-text">2.数据集真实标签通常由数据集提供自带，大部分公开数据集（如MINST，CIFAR-10）都自带有标签，如果我们自己做数据集，也可以自己输入真实标签（比如一张图片-》图片文件名，文件夹名，Excel表名）（那我们使用这些数据集的时候怎么调用这些标签呢？）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9A%E7%94%A8%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%92%8C%E5%AE%9E%E9%99%85%E6%A0%87%E7%AD%BE%E6%9D%A5%E8%AE%A1%E7%AE%97%E6%8D%9F%E5%A4%B1%EF%BC%88%E9%82%A3%E8%BF%99%E4%B8%AA%E5%AE%9E%E9%99%85%E6%A0%87%E7%AD%BE%E6%80%8E%E4%B9%88%E6%9D%A5%E5%AE%9A%E5%91%A2%EF%BC%9F%E8%BF%99%E4%B8%AA%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%A6%82%E6%9E%9C%E4%B8%8D%E7%AC%A6%E5%90%88%E6%A0%87%E7%AD%BE%EF%BC%8C%E4%BD%86%E6%98%AF%E7%A1%AE%E5%AE%9E%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84%EF%BC%8C%E9%82%A3%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%E9%94%99%E8%AF%AF%E7%9A%84%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%8F%88%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E6%8D%9F%E5%A4%B1%EF%BC%8C%E9%82%A3%E8%BF%99%E4%B8%AA%E6%8D%9F%E5%A4%B1%E5%8F%88%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.2.</span> <span class="toc-text">损失函数：用输出层的预测结果和实际标签来计算损失（那这个实际标签怎么来定呢？这个预测结果如果不符合标签，但是确实是正确的，那该怎么办？错误的预测结果又有什么用？如果有损失，那这个损失又有什么用？）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%A0%87%E7%AD%BE%E9%80%9A%E5%B8%B8%E5%9C%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E9%87%8C%E9%9D%A2%EF%BC%8C%E6%AF%94%E5%A6%82%E8%AF%B4%E7%8C%AB%E5%92%8C%E7%8B%97%E8%BF%99%E4%B8%AA%E7%B1%BB%E5%88%AB%EF%BC%8C%E9%80%9A%E5%B8%B8%E6%98%AF%E4%BA%BA%E5%B7%A5%E6%A0%87%E6%B3%A8%E6%88%96%E5%B7%B2%E6%9C%89%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BB%99%E5%87%BA%EF%BC%88%E6%80%8E%E4%B9%88%E6%A0%87%E6%B3%A8%EF%BC%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8D%E6%98%AF%E4%B8%80%E5%BC%A0%E5%BC%A0%E5%9B%BE%E7%89%87%E5%90%97%EF%BC%89"><span class="toc-number">5.1.3.2.1.</span> <span class="toc-text">1.标签通常在数据集里面，比如说猫和狗这个类别，通常是人工标注或已有数据集给出（怎么标注？数据集不是一张张图片吗）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%EF%BC%9A%E4%B8%BA%E6%AF%8F%E5%BC%A0%E5%9B%BE%E9%85%8D%E4%B8%80%E4%B8%AA%E5%9B%BE%E7%89%87%E5%BD%93%E5%81%9A%E6%A0%87%E7%AD%BE%EF%BC%8C%E5%A6%82%E7%8C%AB%E7%8B%97%EF%BC%88%E6%98%AF%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%87%E4%BB%B6%E5%90%97%EF%BC%9F%EF%BC%89%EF%BC%8C%E6%A0%87%E6%B3%A8%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%94%A8%E6%96%87%E4%BB%B6%E5%A4%B9%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%EF%BC%8C%E5%A6%82cat-xxx-jpg%EF%BC%88%E5%B0%B1%E6%98%AF%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%BE%E5%9C%A8%E4%B8%80%E4%B8%AA%E6%A0%87%E7%AD%BE%E5%A6%82cat%E5%91%BD%E5%90%8D%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8C%E5%90%97%EF%BC%8C%E7%84%B6%E5%90%8E%E7%BC%96%E8%AF%91%E5%99%A8%E4%BC%9A%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E6%96%87%E4%BB%B6%E5%90%8D%E4%BD%9C%E4%B8%BA%E6%A0%87%E7%AD%BE%EF%BC%9F%EF%BC%89%E5%A4%8D%E6%9D%82%E4%BB%BB%E5%8A%A1%E5%A6%82%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%92%8C%E5%88%86%E5%89%B2%E6%97%B6%EF%BC%8C%E4%BC%9A%E7%94%A8%E4%B8%93%E9%97%A8%E7%9A%84%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E5%A6%82LabelImg%E3%80%81LabelMe%E7%94%9F%E6%88%90xml%E3%80%81json%E7%AD%89%E6%A0%87%E6%B3%A8%E6%96%87%E4%BB%B6%EF%BC%8C%E8%AE%B0%E5%BD%95%E6%AF%8F%E4%B8%AA%E7%9B%AE%E6%A0%87%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%92%8C%E7%B1%BB%E5%88%AB"><span class="toc-number">5.1.3.2.2.</span> <span class="toc-text">最简单的：为每张图配一个图片当做标签，如猫狗（是创建一个图片的文件吗？），标注也可以用文件夹进行分类，如cat&#x2F;xxx.jpg（就是把数据集放在一个标签如cat命名的文件夹里吗，然后编译器会自动识别文件名作为标签？）复杂任务如目标检测和分割时，会用专门的标注工具如LabelImg、LabelMe生成xml、json等标注文件，记录每个目标的位置和类别</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%A6%82%E6%9E%9C%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E4%B8%8D%E7%AC%A6%E5%90%88%E5%AE%9E%E9%99%85%E6%A0%87%E7%AD%BE%E4%BD%86%E5%8F%88%E6%B2%A1%E6%9C%89%E9%94%99%EF%BC%8C%E9%82%A3%E6%A0%87%E7%AD%BE%E6%98%AF%E9%94%99%E7%9A%84%EF%BC%8C%E8%A6%81%E6%9B%B4%E6%94%B9%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE"><span class="toc-number">5.1.3.2.3.</span> <span class="toc-text">2.如果预测结果不符合实际标签但又没有错，那标签是错的，要更改真实标签</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E9%94%99%E8%AF%AF%E7%9A%84%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E6%8D%9F%E5%A4%B1%E8%BE%83%E5%A4%A7%EF%BC%8C%E6%A8%A1%E5%9E%8B%E4%BC%9A%E7%9F%A5%E9%81%93%E8%87%AA%E5%B7%B1%E5%93%AA%E9%87%8C%E6%9C%89%E9%97%AE%E9%A2%98%EF%BC%8C%E5%B9%B6%E5%9C%A8%E4%BC%9A%E5%9C%A8%E5%90%8E%E7%BB%AD%E8%AE%AD%E7%BB%83%E4%B8%AD%E8%B0%83%E6%95%B4%E5%8F%82%E6%95%B0%EF%BC%8C%E5%87%8F%E5%B0%91%E7%B1%BB%E4%BC%BC%E9%94%99%E8%AF%AF%EF%BC%88%E8%BF%99%E4%B8%AA%E7%9F%A5%E9%81%93%E5%B9%B6%E8%B0%83%E6%95%B4%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F%E6%98%AF%E9%80%9A%E8%BF%87%E6%9F%90%E4%B8%AA%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%A4%A7%E5%B0%8F%E6%9D%A5%E5%AF%B9%E5%8F%82%E6%95%B0%E5%81%9A%E6%9B%B4%E6%94%B9%E5%90%97%EF%BC%9F%EF%BC%8C%E9%82%A3%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%98%AF%E4%B8%8D%E6%98%AF%E8%BF%98%E8%A6%81%E5%8A%A0%E4%B8%8A%E4%B8%80%E4%B8%AA%E9%80%BB%E8%BE%91%EF%BC%8C%E4%BD%BF%E6%AF%8F%E6%AC%A1%E8%AE%AD%E7%BB%83%E7%9A%84%E6%97%B6%E5%80%99%E8%AE%A9%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%BE%80%E6%8D%9F%E5%A4%B1%E5%B0%8F%E7%9A%84%E6%96%B9%E5%90%91%E6%94%B9%E5%8F%98%EF%BC%9F%E9%82%A3%E5%A6%82%E6%9E%9C%E6%98%AF%E8%BF%99%E6%A0%B7%EF%BC%8C%E6%94%B9%E5%8F%98%E7%9A%84%E5%A4%A7%E5%B0%8F%E5%B9%85%E5%BA%A6%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%9F%E5%A4%A7%E5%90%97%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.2.4.</span> <span class="toc-text">3.错误的预测结果的损失较大，模型会知道自己哪里有问题，并在会在后续训练中调整参数，减少类似错误（这个知道并调整的过程是怎么实现的？是通过某个损失的大小来对参数做更改吗？，那模型训练过程中是不是还要加上一个逻辑，使每次训练的时候让模型的参数往损失小的方向改变？那如果是这样，改变的大小幅度是多少？大吗？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%AF%8F%E6%AC%A1%E9%80%9A%E8%BF%87%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%94%A8%E6%A0%B9%E6%8D%AE%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%AE%A1%E7%AE%97%E7%9A%84%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97%E5%87%BA%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E7%9A%84%E6%A2%AF%E5%BA%A6%EF%BC%8C%E6%A0%B9%E6%8D%AE%E6%A2%AF%E5%BA%A6%E5%BE%80%E6%8D%9F%E5%A4%B1%E5%B0%8F%E7%9A%84%E6%96%B9%E5%90%91%E8%B0%83%E6%95%B4%E5%8F%82%E6%95%B0%EF%BC%8C%E5%8F%82%E6%95%B0%E6%94%B9%E5%8F%98%E7%9A%84%E5%B9%85%E5%BA%A6%E7%94%B1%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%86%B3%E5%AE%9A%EF%BC%8C%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%A4%A7%EF%BC%8C%E5%8F%82%E6%95%B0%E6%94%B9%E5%8F%98%E5%B9%85%E5%BA%A6%E5%A4%A7%EF%BC%8C%E5%8F%8D%E4%B9%8B%E5%B0%8F%EF%BC%8C%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A6%81%E9%80%89%E6%8B%A9%E9%80%82%E5%BD%93%EF%BC%8C%E4%B8%8D%E7%84%B6%E6%94%B9%E5%8F%98%E4%BC%9A%E8%BF%87%E5%A4%A7%E6%88%96%E8%80%85%E8%BF%87%E5%B0%8F%EF%BC%88%E5%8D%B3%E5%8F%82%E6%95%B0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%AF%BC%E6%95%B0%EF%BC%89%EF%BC%88%E9%82%A3%E6%A2%AF%E5%BA%A6%E6%98%AF%E4%B8%8D%E6%98%AF%E5%AF%B9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC%EF%BC%8C%E7%84%B6%E5%90%8E%E5%AF%B9%E5%BA%94%E5%8F%82%E6%95%B0%E5%B8%A6%E5%85%A5%E5%AF%BC%E6%95%B0%E4%B8%AD%E5%B0%B1%E6%98%AF%E6%A2%AF%E5%BA%A6%EF%BC%9F%E5%AD%A6%E4%B9%A0%E7%8E%87%E6%98%AF%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E9%80%89%E6%8B%A9%E7%9A%84%E5%90%97%EF%BC%9F%E6%88%91%E4%BB%AC%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.2.5.</span> <span class="toc-text">1.每次通过反向传播用根据前向传播计算的损失计算出每个参数的梯度，根据梯度往损失小的方向调整参数，参数改变的幅度由学习率决定，学习率大，参数改变幅度大，反之小，学习率要选择适当，不然改变会过大或者过小（即参数损失函数的导数）（那梯度是不是对损失函数求导，然后对应参数带入导数中就是梯度？学习率是我们自己选择的吗？我们怎么选择？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E6%8D%9F%E5%A4%B1%E8%B6%8A%E5%A4%A7%EF%BC%8C%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E5%B0%B1%E8%B6%8A%E5%B7%AE%EF%BC%8C%E5%B0%B1%E8%A6%81%E4%BC%98%E5%8C%96%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%B0%B1%E6%98%AF%E5%BC%95%E5%AF%BC%E6%A8%A1%E5%9E%8B%E4%B8%8D%E6%96%AD%E5%9C%B0%E4%BC%98%E5%8C%96"><span class="toc-number">5.1.3.2.6.</span> <span class="toc-text">4.损失越大，模型预测结果就越差，就要优化，损失函数就是引导模型不断地优化</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%9A%E6%A0%B9%E6%8D%AE%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%94%A8%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E8%AE%A1%E7%AE%97%E5%87%BA%E7%9A%84%E6%8D%9F%E5%A4%B1%E6%9D%A5%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E5%AF%B9%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%88%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E5%AF%B9%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%BD%B1%E5%93%8D%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F%E8%BF%99%E6%98%AF%E6%80%8E%E4%B9%88%E8%AE%A1%E7%AE%97%E7%9A%84%EF%BC%9F%E9%82%A3%E8%AE%A1%E7%AE%97%E7%9A%84%E5%BD%B1%E5%93%8D%E7%9A%84%E6%B3%A2%E5%8A%A8%E5%B0%B1%E6%98%AF%E6%A2%AF%E5%BA%A6%E5%90%97%EF%BC%9F%E8%BF%99%E6%A2%AF%E5%BA%A6%E6%9C%89%E4%BB%80%E4%B9%88%E6%84%8F%E4%B9%89%EF%BC%89"><span class="toc-number">5.1.3.3.</span> <span class="toc-text">反向传播：根据损失函数用输出层的预测结果计算出的损失来计算每个参数对损失的影响（计算每个参数对损失的影响有什么作用？这是怎么计算的？那计算的影响的波动就是梯度吗？这梯度有什么意义）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%B0%B1%E6%98%AF%E8%A6%81%E7%9F%A5%E9%81%93%E5%A6%82%E6%9E%9C%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E5%8F%98%E5%A4%A7%E4%B8%80%E7%82%B9%E6%88%96%E8%80%85%E5%8F%98%E5%B0%8F%E4%B8%80%E7%82%B9%EF%BC%8C%E6%8D%9F%E5%A4%B1%E4%BC%9A%E6%80%8E%E4%B9%88%E5%8F%98%E5%8C%96%EF%BC%8C%E5%A5%BD%E9%92%88%E5%AF%B9%E8%B0%83%E6%95%B4%EF%BC%88%E8%BF%99%E4%B8%AA%E6%A3%80%E6%B5%8B%E5%8F%98%E5%8C%96%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E5%9C%A8%E5%BD%93%E5%89%8D%E8%AE%AD%E7%BB%83%E4%B8%AD%E8%BF%9B%E8%A1%8C%EF%BC%8C%E9%82%A3%E6%AF%8F%E6%AC%A1%E5%AF%B9%E4%B8%80%E4%B8%AA%E5%8F%82%E6%95%B0%E5%B7%B2%E7%BB%8F%E6%A3%80%E6%B5%8B%E5%90%8E%E4%BC%9A%E6%8A%8A%E6%89%80%E6%9C%89%E7%BB%93%E6%9E%9C%E5%AD%98%E5%82%A8%E4%B8%80%E8%B5%B7%E5%9C%A8%E4%B8%8B%E4%B8%80%E8%BD%AE%E5%BC%80%E5%A7%8B%E6%97%B6%E8%B0%83%E6%95%B4%E8%BF%98%E6%98%AF%E4%B8%80%E4%B8%AA%E4%B8%AA%E6%A3%80%E6%B5%8B%E4%B8%80%E4%B8%AA%E4%B8%AA%E8%B0%83%E6%95%B4%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.3.1.</span> <span class="toc-text">1.反向传播就是要知道如果每个参数变大一点或者变小一点，损失会怎么变化，好针对调整（这个检测变化的过程是在当前训练中进行，那每次对一个参数已经检测后会把所有结果存储一起在下一轮开始时调整还是一个个检测一个个调整？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%98%AF%E4%B8%80%E6%AC%A1%E6%80%A7%E6%89%B9%E9%87%8F%E5%9C%B0%E5%AF%B9%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6%EF%BC%8C%E7%84%B6%E5%90%8E%E4%BC%98%E5%8C%96%E5%99%A8%E5%86%8D%E4%B8%80%E6%AC%A1%E6%80%A7%E5%AF%B9%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E8%B0%83%E6%95%B4"><span class="toc-number">5.1.3.3.2.</span> <span class="toc-text">1.反向传播是一次性批量地对参数进行计算梯度，然后优化器再一次性对参数进行调整</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%AE%A1%E7%AE%97%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E5%AF%B9%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%BD%B1%E5%93%8D%E6%98%AF%E7%94%A8%E9%93%BE%E5%BC%8F%E6%B3%95%E5%88%99%EF%BC%88%E5%BE%AE%E7%A7%AF%E5%88%86%EF%BC%89%EF%BC%8C%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E5%B7%A5%E5%85%B7%EF%BC%88%E5%A6%82pytorch%EF%BC%8CTensorFlow%EF%BC%89%E8%87%AA%E5%8A%A8%E5%AE%8C%E6%88%90%EF%BC%88%E8%BF%99%E4%B8%AA%E8%BF%87%E7%A8%8B%E5%B0%B1%E6%98%AF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E8%BF%90%E8%A1%8C%E6%93%8D%E4%BD%9C%E5%90%97%EF%BC%9F%E5%85%B7%E4%BD%93%E6%9D%A5%E8%AF%B4pytorch%E5%92%8CTensorFlow%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%93%8D%E4%BD%9C%E7%9A%84%EF%BC%9F%E6%88%91%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.3.3.</span> <span class="toc-text">2.计算每个参数对损失的影响是用链式法则（微积分），自动求导工具（如pytorch，TensorFlow）自动完成（这个过程就是损失函数的运行操作吗？具体来说pytorch和TensorFlow是怎么实现这个操作的？我应该怎么做？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-pytorch%E5%92%8CTensorFlow%E9%83%BD%E6%94%AF%E6%8C%81%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%EF%BC%88autograd%EF%BC%89%EF%BC%8C%E5%8F%AA%E9%9C%80%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%92%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E6%A1%86%E6%9E%B6%E4%BC%9A%E8%87%AA%E5%8A%A8%E8%BF%BD%E8%B8%AA%E8%AE%A1%E7%AE%97%E5%9B%BE%EF%BC%8C%E8%87%AA%E5%8A%A8%E5%AE%8C%E6%88%90%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%92%8C%E6%A2%AF%E5%BA%A6%E8%AE%A1%E7%AE%97%EF%BC%88%E8%BF%99%E9%87%8C%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%92%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9A%E4%B9%89%E7%9A%84%EF%BC%9F%E6%9C%89%E5%9B%BA%E5%AE%9A%E7%9A%84%E6%A8%A1%E7%89%88%E5%90%97%EF%BC%9F%EF%BC%9F%E5%AE%9A%E4%B9%89%E4%B9%8B%E5%90%8E%E5%8F%88%E6%98%AF%E6%80%8E%E4%B9%88%E8%B0%83%E7%94%A8%E7%9A%84%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.3.4.</span> <span class="toc-text">1.pytorch和TensorFlow都支持自动求导（autograd），只需定义网络结构和损失函数，框架会自动追踪计算图，自动完成反向传播和梯度计算（这里网络结构和损失函数是怎么定义的？有固定的模版吗？？定义之后又是怎么调用的？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E4%BB%A5pytorch%E4%B8%BA%E4%BE%8B%EF%BC%8C%E8%B0%83%E7%94%A8%E6%B1%82%E5%AF%BC%EF%BC%9A%EF%BC%88%E8%BF%99%E5%B0%B1%E6%98%AF%E8%BF%99%E5%87%A0%E6%AD%A5%E7%9A%84%E6%89%80%E6%9C%89%E5%86%85%E5%AE%B9%E5%90%97%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.3.5.</span> <span class="toc-text">2.以pytorch为例，调用求导：（这就是这几步的所有内容吗？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%A2%AF%E5%BA%A6%E5%B0%B1%E6%98%AF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E7%9A%84%E5%AF%BC%E6%95%B0%EF%BC%8C%E8%A1%A8%E7%A4%BA%E5%8F%82%E6%95%B0%E6%AF%8F%E5%8F%98%E5%8C%96%E4%B8%80%E7%82%B9%EF%BC%8C%E6%8D%9F%E5%A4%B1%E4%BC%9A%E6%80%8E%E4%B9%88%E5%8F%98%EF%BC%8C%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%96%B9%E5%90%91%E6%8C%87%E5%90%91%E6%8D%9F%E5%A4%B1%E5%A2%9E%E5%8A%A0%E6%9C%80%E5%BF%AB%E7%9A%84%E6%96%B9%E5%90%91%EF%BC%8C%E6%88%91%E4%BB%AC%E8%A6%81%E5%8F%8D%E6%A2%AF%E5%BA%A6%E6%96%B9%E5%90%91%E8%B0%83%E6%95%B4%E5%8F%82%E6%95%B0%EF%BC%8C%E8%AE%A9%E6%8D%9F%E5%A4%B1%E5%8F%98%E5%B0%8F%EF%BC%88%E9%82%A3%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%B0%B1%E6%98%AF%E5%AF%B9%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E6%B1%82%E5%AF%BC%EF%BC%8C%E7%84%B6%E5%90%8E%E7%9C%8B%E5%8F%82%E6%95%B0%E7%9A%84%E5%8F%98%E5%8C%96%E7%8E%87%E5%90%97%EF%BC%9F%E5%86%8D%E5%92%8C%E7%9C%9F%E5%AE%9E%E6%A0%87%E7%AD%BE%E8%BF%9B%E8%A1%8C%E6%AF%94%E8%BE%83%EF%BC%9F%E9%82%A3%E5%8F%82%E6%95%B0%E5%AE%9E%E9%99%85%E6%98%AF%E5%87%BD%E6%95%B0%E9%87%8C%E9%9D%A2%E7%9A%84%E4%B8%80%E4%B8%AA%E8%87%AA%E5%8F%98%E9%87%8F%E5%90%97%E6%89%80%E4%BB%A5%E6%89%8D%E8%83%BD%E6%B1%82%E5%AF%BC%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.3.6.</span> <span class="toc-text">3.梯度就是损失函数对每个参数的导数，表示参数每变化一点，损失会怎么变，梯度的方向指向损失增加最快的方向，我们要反梯度方向调整参数，让损失变小（那损失函数就是对每个参数求导，然后看参数的变化率吗？再和真实标签进行比较？那参数实际是函数里面的一个自变量吗所以才能求导？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%98%AF%E7%9A%84%EF%BC%8C%E5%8F%82%E6%95%B0%E5%B0%B1%E6%98%AF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E8%87%AA%E5%8F%98%E9%87%8F%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AF%E4%BB%A5%E5%AF%B9%E5%85%B6%E8%BF%9B%E8%A1%8C%E6%B1%82%E5%AF%BC%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%B0%B1%E6%98%AF%E5%AF%B9%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E6%B1%82%E5%AF%BC%EF%BC%8C%E8%AF%B4%E7%99%BD%E4%BA%86%E5%B0%B1%E6%98%AF%E5%AF%B9%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC%EF%BC%8C%E5%AF%B9%E5%BA%94%E6%A2%AF%E5%BA%A6%E5%B0%B1%E6%98%AF%E5%AF%B9%E5%BA%94%E7%9A%84%E5%8F%82%E6%95%B0%E5%B8%A6%E5%85%A5%E5%AF%BC%E5%87%BD%E6%95%B0"><span class="toc-number">5.1.3.3.7.</span> <span class="toc-text">1.是的，参数就是损失函数的自变量，所以可以对其进行求导，损失函数就是对每个参数求导，说白了就是对损失函数求导，对应梯度就是对应的参数带入导函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%EF%BC%9A%E5%88%A9%E7%94%A8%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%AE%A1%E7%AE%97%E5%87%BA%E7%9A%84%E5%BA%A6%EF%BC%8C%E6%9B%B4%E6%96%B0%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E4%BD%BF%E6%A8%A1%E5%9E%8B%E8%A1%A8%E7%8E%B0%E6%9B%B4%E5%A5%BD%EF%BC%88%E8%BF%99%E5%B0%B1%E6%98%AF%E8%AF%B4%E7%8E%B0%E5%9C%A8%E8%BF%98%E6%98%AF%E5%A4%84%E4%BA%8E%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E5%AF%B9%E5%90%A7%EF%BC%8C%E6%80%8E%E4%B9%88%E8%83%BD%E9%80%9A%E8%BF%87%E6%A2%AF%E5%BA%A6%E6%9D%A5%E6%9B%B4%E6%96%B0%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%9F%E5%AE%9E%E9%99%85%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%A4%A7%E5%B0%8F%E6%9D%A5%E5%AE%9A%E7%9A%84%E5%90%97%EF%BC%9F%E9%82%A3%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8F%82%E6%95%B0%E6%98%AF%E6%80%8E%E4%B9%88%E5%BD%A2%E6%88%90%E7%9A%84%EF%BC%9F%E6%98%AF%E8%87%AA%E5%B7%B1%E8%BE%93%E5%85%A5%E7%9A%84%E5%90%97%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.</span> <span class="toc-text">优化器：利用反向传播计算出的度，更新网络中的参数，使模型表现更好（这就是说现在还是处于模型训练阶段对吧，怎么能通过梯度来更新网络中的参数？实际是根据每个参数损失函数大小来定的吗？那第一次训练的参数是怎么形成的？是自己输入的吗？）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%98%AF%E7%9A%84%EF%BC%8C%E4%BC%98%E5%8C%96%E5%99%A8%E6%98%AF%E7%94%A8%E4%BA%8E%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E7%9A%84"><span class="toc-number">5.1.3.4.1.</span> <span class="toc-text">1.是的，优化器是用于训练阶段的</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E9%80%9A%E8%BF%87%E6%A2%AF%E5%BA%A6%E6%9D%A5%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0%E7%9A%84%E5%85%B7%E4%BD%93%E6%93%8D%E4%BD%9C%E6%98%AF%EF%BC%9A%E6%96%B0%E5%8F%82%E6%95%B0-%E6%97%A7%E5%8F%82%E6%95%B0-%E5%AD%A6%E4%B9%A0%E7%8E%87-%E6%A2%AF%E5%BA%A6%EF%BC%88%E8%BF%99%E4%B8%AA%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%9A%E8%BF%87%E8%BF%99%E4%B8%AA%E5%85%AC%E5%BC%8F%E5%B0%B1%E8%83%BD%E6%9B%B4%E6%96%B0%E5%8F%82%E6%95%B0%EF%BC%8C%E5%85%B7%E4%BD%93%E7%9A%84%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.2.</span> <span class="toc-text">2.通过梯度来更新参数的具体操作是：新参数&#x3D;旧参数-学习率*梯度（这个学习率又是什么，为什么通过这个公式就能更新参数，具体的原理是什么？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%AD%A6%E4%B9%A0%E7%8E%87%E6%98%AF%E4%B8%80%E4%B8%AA%E8%B6%85%E5%8F%82%E6%95%B0%EF%BC%8C%E7%94%A8%E6%9D%A5%E6%8E%A7%E5%88%B6%E6%AF%8F%E6%AC%A1%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E7%9A%84%E6%AD%A5%E9%95%BF%EF%BC%8C%E5%8D%B3%E5%8F%98%E5%8C%96%E5%B9%85%E5%BA%A6%EF%BC%8C%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%BF%87%E5%A4%A7%EF%BC%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C%E4%B8%8D%E7%A8%B3%E5%AE%9A%EF%BC%8C%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%BF%87%E5%B0%8F%EF%BC%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E8%AE%AD%E7%BB%83%E8%BF%87%E6%85%A2%EF%BC%8C%E5%AF%BC%E8%87%B4%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%83%BD%E6%9C%80%E7%BB%88%E9%99%B7%E5%85%A5%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%EF%BC%88%E5%A7%8B%E7%BB%88%E5%9C%A8%E6%9F%90%E4%B8%80%E5%9D%97%E5%B1%80%E9%83%A8%E8%AE%AD%E7%BB%83%EF%BC%89"><span class="toc-number">5.1.3.4.3.</span> <span class="toc-text">1.学习率是一个超参数，用来控制每次参数更新的步长，即变化幅度，学习率过大，会导致训练结果不稳定，学习率过小，会导致训练过慢，导致结果可能最终陷入局部最优（始终在某一块局部训练）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%9B%B4%E6%96%B0%E5%8F%82%E8%80%83%E5%85%AC%E5%BC%8F%EF%BC%9A"><span class="toc-number">5.1.3.4.4.</span> <span class="toc-text">2.更新参考公式：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%8F%82%E6%95%B0%E6%98%AF%E6%A0%B9%E6%8D%AE%E6%A2%AF%E5%BA%A6%E6%9D%A5%E5%AE%9A%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E6%8D%9F%E5%A4%B1%E6%9C%AC%E8%BA%AB%EF%BC%88%E5%8F%82%E6%95%B0%E7%9A%84%E5%AF%BC%E6%95%B0%EF%BC%9F%E9%82%A3%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6%E6%98%AF%E4%B8%8D%E6%98%AF%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E5%AE%9E%E9%99%85%E5%8F%AA%E6%98%AF%E7%94%A8%E6%9D%A5%E5%8F%8D%E5%90%91%E9%81%8D%E5%8E%86%E4%B8%80%E9%81%8D%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%8C%E7%84%B6%E5%90%8E%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AF%B9%E6%A2%AF%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97%E8%B5%B7%E5%86%B3%E5%AE%9A%E4%BD%9C%E7%94%A8%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.5.</span> <span class="toc-text">3.参数是根据梯度来定，而不是损失本身（参数的导数？那计算梯度是不是反向传播的作用实际只是用来反向遍历一遍每个参数，然后损失函数对梯度的计算起决定作用？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%98%AF%E7%9A%84%EF%BC%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E6%A0%B8%E5%BF%83%E6%98%AF%E5%88%A9%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%8F%E4%B8%AA%E5%8F%82%E6%95%B0%E6%B1%82%E5%AF%BC%E6%B1%82%E5%87%BA%E6%A2%AF%E5%BA%A6%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%BD%A2%E5%BC%8F%E5%86%B3%E5%AE%9A%E4%BA%86%E6%A2%AF%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F%E5%92%8C%E6%95%B0%E5%80%BC%EF%BC%8C%E6%A2%AF%E5%BA%A6%E7%9A%84%E5%A4%A7%E5%B0%8F%E5%92%8C%E6%96%B9%E5%90%91%E7%9B%B4%E6%8E%A5%E5%BD%B1%E5%93%8D%E5%8F%82%E6%95%B0%E7%9A%84%E6%9B%B4%E6%96%B0%EF%BC%88%E9%82%A3%E8%BF%99%E6%A0%B7%E6%8D%9F%E5%A4%B1%E5%8F%88%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F%E7%9B%B4%E6%8E%A5%E6%B1%82%E6%A2%AF%E5%BA%A6%E4%B8%8D%E5%B0%B1%E8%A1%8C%E4%BA%86%EF%BC%8C%E6%A0%B9%E6%8D%AE%E6%A2%AF%E5%BA%A6%E6%9D%A5%E8%BF%9B%E8%A1%8C%E4%BC%98%E5%8C%96%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%BD%A2%E5%BC%8F%E6%80%8E%E4%B9%88%E5%AE%9A%E4%B9%89%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.6.</span> <span class="toc-text">1.是的，反向传播的核心是利用损失函数对每个参数求导求出梯度，损失函数的形式决定了梯度的计算方式和数值，梯度的大小和方向直接影响参数的更新（那这样损失又有什么用？直接求梯度不就行了，根据梯度来进行优化，损失函数的形式怎么定义，有哪些？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8F%82%E6%95%B0%E4%B8%80%E8%88%AC%E6%98%AF%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%EF%BC%8C%E7%94%B1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E4%B8%80%E7%BB%84%E5%88%9D%E5%A7%8B%E5%8F%82%E6%95%B0%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF%E5%BE%88%E5%B0%8F%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%EF%BC%89%EF%BC%88%E8%BF%99%E6%98%AF%E6%80%8E%E4%B9%88%E7%94%9F%E6%88%90%E7%9A%84%EF%BC%9F%E6%97%A2%E7%84%B6%E6%9C%89%E5%8F%82%E6%95%B0%EF%BC%8C%E9%82%A3%E5%BA%94%E8%AF%A5%E4%B9%9F%E6%9C%89%E5%AF%BC%E5%85%A5%E5%8F%82%E6%95%B0%E7%9A%84%E5%8F%98%E9%87%8F%E5%90%A7%EF%BC%8C%E9%82%A3%E5%8F%98%E9%87%8F%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%8C%E6%98%AF%E6%80%8E%E4%B9%88%E7%94%A8%E7%9A%84%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.7.</span> <span class="toc-text">4.第一次训练的参数一般是随机初始化的，由深度学习框架自动生成一组初始参数（通常是很小的随机数）（这是怎么生成的？既然有参数，那应该也有导入参数的变量吧，那变量在哪里，是怎么用的？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%A1%86%E6%9E%B6%E4%BC%9A%E8%87%AA%E5%8A%A8%E4%B8%BA%E6%AF%8F%E4%B8%80%E5%B1%82%E5%8F%82%E6%95%B0%E5%88%86%E9%85%8D%E5%8F%98%E9%87%8F%EF%BC%8C%E5%B9%B6%E7%94%A8%E7%89%B9%E5%AE%9A%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E5%A6%82%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E3%80%81%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%E3%80%81Xavier%E3%80%81He%E5%88%9D%E5%A7%8B%E5%8C%96%E7%AD%89%EF%BC%89%E7%94%9F%E6%88%90%E5%88%9D%E5%A7%8B%E5%80%BC%EF%BC%8C%E8%BF%99%E6%A0%B7%E6%98%AF%E8%AE%A9%E7%BD%91%E7%BB%9C%E4%B8%80%E5%BC%80%E5%A7%8B%E5%B0%B1%E6%9C%89%E5%A4%9A%E6%A0%B7%E6%80%A7%EF%BC%8C%E9%81%BF%E5%85%8D%E6%89%80%E6%9C%89%E7%A5%9E%E7%BB%8F%E5%85%83%E5%AD%A6%E5%88%B0%E4%B8%80%E6%A0%B7%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%88%E8%BF%99%E9%87%8C%E7%A5%9E%E7%BB%8F%E5%85%83%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%81%BF%E5%85%8D%E6%89%80%E6%9C%89%E7%A5%9E%E7%BB%8F%E5%85%83%E5%AD%A6%E5%88%B0%E4%B8%80%E6%A0%B7%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%9F%EF%BC%89"><span class="toc-number">5.1.3.4.8.</span> <span class="toc-text">1.框架会自动为每一层参数分配变量，并用特定的方法（如高斯分布、均匀分布、Xavier、He初始化等）生成初始值，这样是让网络一开始就有多样性，避免所有神经元学到一样的东西（这里神经元是什么？为什么要避免所有神经元学到一样的东西？）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%8F%AA%E9%9C%80%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8C%E6%A1%86%E6%9E%B6%E5%B0%B1%E4%BC%9A%E8%87%AA%E5%8A%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0"><span class="toc-number">5.1.3.4.9.</span> <span class="toc-text">2.只需定义网络结构，框架就会自动初始化参数</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/05/10/%E7%99%BE%E9%A2%98%E6%8B%BE%E9%81%97/%E7%99%BE%E9%A2%98%20%E5%85%B6%E4%B8%89/" title="百题 其三"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512575.jpg" onerror="this.onerror=null;this.src='/images/404.jpg'" alt="百题 其三"/></a><div class="content"><a class="title" href="/2025/05/10/%E7%99%BE%E9%A2%98%E6%8B%BE%E9%81%97/%E7%99%BE%E9%A2%98%20%E5%85%B6%E4%B8%89/" title="百题 其三">百题 其三</a><time datetime="2025-05-09T16:00:00.000Z" title="发表于 2025-05-10 00:00:00">2025-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%89%20OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" title="深度学习 其三 OpenCV图像处理"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512122.jpg" onerror="this.onerror=null;this.src='/images/404.jpg'" alt="深度学习 其三 OpenCV图像处理"/></a><div class="content"><a class="title" href="/2025/04/28/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%E5%85%B6%E4%B8%89%20OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" title="深度学习 其三 OpenCV图像处理">深度学习 其三 OpenCV图像处理</a><time datetime="2025-04-27T16:00:00.000Z" title="发表于 2025-04-28 00:00:00">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/27/C++%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%AD%A6%E4%B9%A0/C++%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%20%E5%85%B6%E4%B8%80%20%E8%B5%B0%E8%BF%B7%E5%AE%AB/" title="C++面向对象 其一 走迷宫"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512695.jpg" onerror="this.onerror=null;this.src='/images/404.jpg'" alt="C++面向对象 其一 走迷宫"/></a><div class="content"><a class="title" href="/2025/04/27/C++%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%AD%A6%E4%B9%A0/C++%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%20%E5%85%B6%E4%B8%80%20%E8%B5%B0%E8%BF%B7%E5%AE%AB/" title="C++面向对象 其一 走迷宫">C++面向对象 其一 走迷宫</a><time datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/27/%E5%A4%87%E8%B5%9B/%E5%A4%87%E8%B5%9B%20%E5%85%B6%E4%B8%80%20%20%20%E6%B9%96%E5%8C%97%E4%BF%A1%E5%88%9B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="备赛 其一 湖北信创人工智能"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071511317.jpg" onerror="this.onerror=null;this.src='/images/404.jpg'" alt="备赛 其一 湖北信创人工智能"/></a><div class="content"><a class="title" href="/2025/04/27/%E5%A4%87%E8%B5%9B/%E5%A4%87%E8%B5%9B%20%E5%85%B6%E4%B8%80%20%20%20%E6%B9%96%E5%8C%97%E4%BF%A1%E5%88%9B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" title="备赛 其一 湖北信创人工智能">备赛 其一 湖北信创人工智能</a><time datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%20%E5%85%B6%E4%BA%8C%20%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="深度学习 其二 神经网络和卷积神经网络"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/202504071512122.jpg" onerror="this.onerror=null;this.src='/images/404.jpg'" alt="深度学习 其二 神经网络和卷积神经网络"/></a><div class="content"><a class="title" href="/2025/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20%20%E5%85%B6%E4%BA%8C%20%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="深度学习 其二 神经网络和卷积神经网络">深度学习 其二 神经网络和卷积神经网络</a><time datetime="2025-04-26T16:00:00.000Z" title="发表于 2025-04-27 00:00:00">2025-04-27</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.0.4/img/badge/安知鱼-上班摸鱼中.svg" alt="距离月入25k也就还差一个大佬带我~" title="距离月入25k也就还差一个大佬带我~"/><div id="runtimeTextTip"></div></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title="博客框架为Hexo_v5.4.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v5.4.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.9/img/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="fufhaha" target="_blank">fufhaha</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">0</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/帝君喝茶.gif" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/images/404.jpg&quot;" data-lazy-src="/images/茶水.gif" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/c/" style="font-size: 0.88rem;">c++<sup>1</sup></a><a href="/tags/c-c/" style="font-size: 0.88rem;">c/c++<sup>11</sup></a><a href="/tags/%E5%88%B7%E9%A2%98/" style="font-size: 0.88rem;">刷题<sup>3</sup></a><a href="/tags/%E5%8C%97%E8%88%AA/" style="font-size: 0.88rem;">北航<sup>6</sup></a><a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 0.88rem;">博客<sup>1</sup></a><a href="/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">图像识别算法<sup>4</sup></a><a href="/tags/%E5%A4%87%E8%B5%9B/" style="font-size: 0.88rem;">备赛<sup>1</sup></a><a href="/tags/%E5%A4%A9%E6%A2%AF%E8%B5%9B/" style="font-size: 0.88rem;">天梯赛<sup>1</sup></a><a href="/tags/%E5%AE%9E%E6%88%98/" style="font-size: 0.88rem;">实战<sup>2</sup></a><a href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/" style="font-size: 0.88rem;">嵌入式<sup>1</sup></a><a href="/tags/%E6%8C%87%E5%8D%97/" style="font-size: 0.88rem;">指南<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">数据结构<sup>1</sup></a><a href="/tags/%E6%96%B0%E9%A2%86%E5%9F%9F/" style="font-size: 0.88rem;">新领域<sup>1</sup></a><a href="/tags/%E6%B4%9B%E8%B0%B7/" style="font-size: 0.88rem;">洛谷<sup>3</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem;">深度学习<sup>4</sup></a><a href="/tags/%E6%B8%B8%E6%88%8F%E5%B0%8F%E9%A1%B9%E7%9B%AE/" style="font-size: 0.88rem;">游戏小项目<sup>1</sup></a><a href="/tags/%E6%B9%96%E5%8D%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6/" style="font-size: 0.88rem;">湖南工业大学<sup>1</sup></a><a href="/tags/%E7%AC%94%E8%AE%B0/" style="font-size: 0.88rem;">笔记<sup>13</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>6</sup></a><a href="/tags/%E8%93%9D%E6%A1%A5%E6%9D%AF/" style="font-size: 0.88rem;">蓝桥杯<sup>1</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE%E8%AE%B2%E8%A7%A3/" style="font-size: 0.88rem;">项目讲解<sup>2</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("2024/10/07 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 fufhaha 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async="async">(function () {
  var grt = new Date("2024/10/07 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      if (img != null) {
        img.src = "https://npm.elemecdn.com/anzhiyu-blog@2.0.4/img/badge/安知鱼-下班啦.svg";
        img.title = "下班了就该开开心心的玩耍，嘿嘿~";
        img.alt = "下班了就该开开心心的玩耍，嘿嘿~";
      }

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="深度学习,图像识别算法"></div><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script defer="defer" id="ribbon" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>